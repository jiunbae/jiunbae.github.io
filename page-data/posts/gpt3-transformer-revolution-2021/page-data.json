{"componentChunkName":"component---src-templates-post-tsx","path":"/posts/gpt3-transformer-revolution-2021/","result":{"data":{"markdownRemark":{"html":"<h1 id=\"gpt-3-api를-처음-써본-날\">GPT-3 API를 처음 써본 날</h1>\n<p>2021년 6월, OpenAI가 GPT-3 API를 공개했습니다. 회사 슬랙에 누군가 공유한 링크를 보고, 저도 바로 API 접근 신청을 했습니다. 며칠 후 승인 메일을 받았을 때의 설렘이 아직도 기억납니다.</p>\n<h2 id=\"처음-api를-호출했을-때\">처음 API를 호출했을 때</h2>\n<p>API 키를 받자마자 터미널을 열고 여러 가지를 테스트해봤습니다. 번역, 요약, 코드 생성, 질의응답 등 생각나는 대로 시도해봤습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> openai\n\nopenai<span class=\"token punctuation\">.</span>api_key <span class=\"token operator\">=</span> <span class=\"token string\">\"sk-...\"</span>\n\nresponse <span class=\"token operator\">=</span> openai<span class=\"token punctuation\">.</span>Completion<span class=\"token punctuation\">.</span>create<span class=\"token punctuation\">(</span>\n    engine<span class=\"token operator\">=</span><span class=\"token string\">\"davinci\"</span><span class=\"token punctuation\">,</span>\n    prompt<span class=\"token operator\">=</span><span class=\"token string\">\"Translate English to Korean:\\n\\nEnglish: Hello, how are you?\\nKorean:\"</span><span class=\"token punctuation\">,</span>\n    max_tokens<span class=\"token operator\">=</span><span class=\"token number\">50</span><span class=\"token punctuation\">,</span>\n    temperature<span class=\"token operator\">=</span><span class=\"token number\">0.3</span>\n<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>response<span class=\"token punctuation\">.</span>choices<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>text<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># 출력: 안녕하세요, 어떻게 지내세요?</span></code></pre></div>\n<p>솔직히 첫 결과를 보고 놀랐습니다. 단순한 API 호출 몇 줄로 이런 품질의 번역이 나온다는 것이 믿기 어려웠습니다.</p>\n<h2 id=\"few-shot-learning의-신비\">Few-shot Learning의 신비</h2>\n<p>가장 인상 깊었던 것은 few-shot learning 능력이었습니다. 별도의 학습 과정 없이, 프롬프트에 예시 몇 개만 보여주면 패턴을 파악하고 따라하는 것을 직접 확인했습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">prompt <span class=\"token operator\">=</span> <span class=\"token triple-quoted-string string\">\"\"\"\n프로그래밍 언어와 그 창시자:\nPython: Guido van Rossum\nJava: James Gosling\nC++: Bjarne Stroustrup\nRuby:\"\"\"</span>\n\nresponse <span class=\"token operator\">=</span> openai<span class=\"token punctuation\">.</span>Completion<span class=\"token punctuation\">.</span>create<span class=\"token punctuation\">(</span>\n    engine<span class=\"token operator\">=</span><span class=\"token string\">\"davinci\"</span><span class=\"token punctuation\">,</span>\n    prompt<span class=\"token operator\">=</span>prompt<span class=\"token punctuation\">,</span>\n    max_tokens<span class=\"token operator\">=</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span>\n    temperature<span class=\"token operator\">=</span><span class=\"token number\">0</span>\n<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>response<span class=\"token punctuation\">.</span>choices<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>text<span class=\"token punctuation\">.</span>strip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># 출력: Yukihiro Matsumoto</span></code></pre></div>\n<p>세 가지 예시만 보여줬는데, Ruby의 창시자를 정확하게 답했습니다. 이 정보가 학습 데이터에 있었겠지만, 패턴만 보고 적절한 형식으로 답변한다는 것이 신기했습니다. 마치 모델이 \"아, 프로그래밍 언어와 창시자를 매핑하는 문제구나\"라고 이해한 것처럼 느껴졌습니다.</p>\n<p>더 복잡한 예제도 시도해봤습니다:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">prompt <span class=\"token operator\">=</span> <span class=\"token triple-quoted-string string\">\"\"\"\n다음 문장의 감정을 분석해주세요.\n\n문장: 오늘 정말 기분이 좋아요!\n감정: 긍정\n\n문장: 이 영화는 시간 낭비였어요.\n감정: 부정\n\n문장: 내일 날씨가 어떨까요?\n감정: 중립\n\n문장: 이 제품 때문에 너무 화가 나요.\n감정:\"\"\"</span>\n\nresponse <span class=\"token operator\">=</span> openai<span class=\"token punctuation\">.</span>Completion<span class=\"token punctuation\">.</span>create<span class=\"token punctuation\">(</span>\n    engine<span class=\"token operator\">=</span><span class=\"token string\">\"davinci\"</span><span class=\"token punctuation\">,</span>\n    prompt<span class=\"token operator\">=</span>prompt<span class=\"token punctuation\">,</span>\n    max_tokens<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span>\n    temperature<span class=\"token operator\">=</span><span class=\"token number\">0</span>\n<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>response<span class=\"token punctuation\">.</span>choices<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>text<span class=\"token punctuation\">.</span>strip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># 출력: 부정</span></code></pre></div>\n<p>감정 분석 모델을 별도로 학습시키지 않아도, 예시 세 개만으로 새로운 문장의 감정을 분류할 수 있었습니다.</p>\n<h2 id=\"회사에서의-반응\">회사에서의 반응</h2>\n<p>당시 팀 내 반응은 두 갈래로 나뉘었습니다.</p>\n<p>한쪽에서는 \"이거 우리 일자리 없어지는 거 아니야?\"라는 우려가 있었습니다. 특히 NLP 관련 업무를 하던 동료들이 신경을 많이 썼습니다. 모델 학습 없이 API 호출만으로 상당한 수준의 결과가 나오니, 자신들의 역할이 축소될 것 같다는 불안감이었습니다.</p>\n<p>반대쪽에서는 \"아직 프로덕션에 쓰기엔 무리\"라는 의견이 있었습니다. 결과가 일관적이지 않고, 가끔 완전히 틀린 답을 자신있게 내놓는다는 점이 문제였습니다.</p>\n<p>저는 중간쯤에 있었습니다. 분명 대단한 기술이지만, 당장 모든 것을 대체할 수준은 아니라고 봤습니다.</p>\n<h2 id=\"실제-업무에-적용해본-결과\">실제 업무에 적용해본 결과</h2>\n<p>몇 가지 실제 태스크에 GPT-3를 적용해봤습니다.</p>\n<h3 id=\"시도-1-고객-문의-분류\">시도 1: 고객 문의 분류</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">classify_inquiry</span><span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    prompt <span class=\"token operator\">=</span> <span class=\"token string-interpolation\"><span class=\"token string\">f\"\"\"다음 고객 문의를 카테고리로 분류해주세요.\n카테고리: 결제, 배송, 환불, 제품문의, 기타\n\n문의: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>text<span class=\"token punctuation\">}</span></span><span class=\"token string\">\n카테고리:\"\"\"</span></span>\n\n    response <span class=\"token operator\">=</span> openai<span class=\"token punctuation\">.</span>Completion<span class=\"token punctuation\">.</span>create<span class=\"token punctuation\">(</span>\n        engine<span class=\"token operator\">=</span><span class=\"token string\">\"davinci\"</span><span class=\"token punctuation\">,</span>\n        prompt<span class=\"token operator\">=</span>prompt<span class=\"token punctuation\">,</span>\n        max_tokens<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span>\n        temperature<span class=\"token operator\">=</span><span class=\"token number\">0</span>\n    <span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> response<span class=\"token punctuation\">.</span>choices<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>text<span class=\"token punctuation\">.</span>strip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 테스트</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>classify_inquiry<span class=\"token punctuation\">(</span><span class=\"token string\">\"주문한 상품이 언제 도착하나요?\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># 출력: 배송</span></code></pre></div>\n<p>간단한 분류는 꽤 잘 작동했습니다. 하지만 문제가 있었습니다:</p>\n<ol>\n<li><strong>일관성 부족</strong>: 같은 문의에 대해 가끔 다른 답변이 나왔습니다.</li>\n<li><strong>비용</strong>: 문의량이 많으면 API 비용이 상당했습니다.</li>\n<li><strong>속도</strong>: 실시간 서비스에 넣기엔 latency가 길었습니다.</li>\n</ol>\n<h3 id=\"시도-2-코드-생성\">시도 2: 코드 생성</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">prompt <span class=\"token operator\">=</span> <span class=\"token triple-quoted-string string\">\"\"\"\nPython 함수를 작성해주세요.\n함수명: calculate_fibonacci\n입력: n (정수)\n출력: n번째 피보나치 수\n\n함수:\n```python\n\"\"\"</span>\n\nresponse <span class=\"token operator\">=</span> openai<span class=\"token punctuation\">.</span>Completion<span class=\"token punctuation\">.</span>create<span class=\"token punctuation\">(</span>\n    engine<span class=\"token operator\">=</span><span class=\"token string\">\"davinci-codex\"</span><span class=\"token punctuation\">,</span>\n    prompt<span class=\"token operator\">=</span>prompt<span class=\"token punctuation\">,</span>\n    max_tokens<span class=\"token operator\">=</span><span class=\"token number\">200</span><span class=\"token punctuation\">,</span>\n    temperature<span class=\"token operator\">=</span><span class=\"token number\">0</span>\n<span class=\"token punctuation\">)</span></code></pre></div>\n<p>코드 생성은 인상적이었습니다. 특히 Codex 모델은 프로그래밍 관련 작업에서 높은 품질을 보여줬습니다. 다만 생성된 코드를 그대로 쓰기보다는 참고용으로 활용하는 것이 적절했습니다.</p>\n<h2 id=\"기술적으로-놀라웠던-점\">기술적으로 놀라웠던 점</h2>\n<p>175B(1,750억) 파라미터라는 규모 자체가 충격이었습니다. GPT-2가 1.5B였으니 100배 넘게 커진 것입니다. 단순히 크기만 키웠을 뿐인데 이전에 없던 능력들이 나타났습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># GPT-2 vs GPT-3 파라미터 비교</span>\ngpt2_params <span class=\"token operator\">=</span> <span class=\"token number\">1.5e9</span>   <span class=\"token comment\"># 1.5B</span>\ngpt3_params <span class=\"token operator\">=</span> <span class=\"token number\">175e9</span>   <span class=\"token comment\"># 175B</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"GPT-3는 GPT-2보다 </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>gpt3_params <span class=\"token operator\">/</span> gpt2_params<span class=\"token punctuation\">:</span><span class=\"token format-spec\">.0f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">배 큽니다\"</span></span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># 출력: GPT-3는 GPT-2보다 117배 큽니다</span></code></pre></div>\n<p>이런 현상을 **Emergent Abilities(창발적 능력)**라고 부른다는 것을 나중에 알게 되었습니다. 작은 모델에서는 전혀 보이지 않던 능력이 모델이 충분히 커지면 갑자기 나타난다는 개념입니다. 정확히 왜 이런 현상이 발생하는지는 아직도 완전히 규명되지 않았습니다.</p>\n<h2 id=\"당시의-예측과-실제\">당시의 예측과 실제</h2>\n<p>그때 몇 가지 예측을 했었는데, 맞은 것도 있고 틀린 것도 있습니다.</p>\n<h3 id=\"맞은-예측\">맞은 예측</h3>\n<ul>\n<li>\"앞으로 몇 년 안에 엄청난 발전이 있을 것\" → 2022년 ChatGPT, 2023년 GPT-4로 현실이 되었습니다.</li>\n<li>\"프롬프트 엔지니어링이 중요해질 것\" → 실제로 프롬프트를 어떻게 작성하느냐에 따라 결과 품질이 크게 달라졌습니다.</li>\n</ul>\n<h3 id=\"틀린-예측\">틀린 예측</h3>\n<ul>\n<li>\"API 비용이 내려가면 다들 OpenAI API를 쓰겠지\" → 오픈소스 모델들이 빠르게 따라잡았습니다. LLaMA가 나온 이후로는 직접 모델을 운영하는 것이 더 합리적인 경우도 많아졌습니다.</li>\n<li>\"Hallucination 문제가 금방 해결될 것\" → 2024년 현재까지도 완전히 해결되지 않았습니다.</li>\n</ul>\n<h2 id=\"개인적인-영향\">개인적인 영향</h2>\n<p>GPT-3 이후로 AI에 대한 관심의 폭이 넓어졌습니다. 그전까지는 주로 컴퓨터 비전 쪽만 보고 있었는데, NLP 분야도 본격적으로 공부하기 시작했습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 당시 공부하면서 작성한 Transformer 구현 일부</span>\n<span class=\"token keyword\">import</span> torch\n<span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>nn <span class=\"token keyword\">as</span> nn\n<span class=\"token keyword\">import</span> math\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">MultiHeadAttention</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> d_model<span class=\"token punctuation\">,</span> num_heads<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>d_model <span class=\"token operator\">=</span> d_model\n        self<span class=\"token punctuation\">.</span>num_heads <span class=\"token operator\">=</span> num_heads\n        self<span class=\"token punctuation\">.</span>d_k <span class=\"token operator\">=</span> d_model <span class=\"token operator\">//</span> num_heads\n\n        self<span class=\"token punctuation\">.</span>W_q <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>d_model<span class=\"token punctuation\">,</span> d_model<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>W_k <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>d_model<span class=\"token punctuation\">,</span> d_model<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>W_v <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>d_model<span class=\"token punctuation\">,</span> d_model<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>W_o <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>d_model<span class=\"token punctuation\">,</span> d_model<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">scaled_dot_product_attention</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> Q<span class=\"token punctuation\">,</span> K<span class=\"token punctuation\">,</span> V<span class=\"token punctuation\">,</span> mask<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        scores <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>matmul<span class=\"token punctuation\">(</span>Q<span class=\"token punctuation\">,</span> K<span class=\"token punctuation\">.</span>transpose<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> math<span class=\"token punctuation\">.</span>sqrt<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>d_k<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> mask <span class=\"token keyword\">is</span> <span class=\"token keyword\">not</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n            scores <span class=\"token operator\">=</span> scores<span class=\"token punctuation\">.</span>masked_fill<span class=\"token punctuation\">(</span>mask <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1e9</span><span class=\"token punctuation\">)</span>\n        attn <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>softmax<span class=\"token punctuation\">(</span>scores<span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> torch<span class=\"token punctuation\">.</span>matmul<span class=\"token punctuation\">(</span>attn<span class=\"token punctuation\">,</span> V<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> Q<span class=\"token punctuation\">,</span> K<span class=\"token punctuation\">,</span> V<span class=\"token punctuation\">,</span> mask<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        batch_size <span class=\"token operator\">=</span> Q<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n\n        Q <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>W_q<span class=\"token punctuation\">(</span>Q<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>num_heads<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>d_k<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>transpose<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n        K <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>W_k<span class=\"token punctuation\">(</span>K<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>num_heads<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>d_k<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>transpose<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n        V <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>W_v<span class=\"token punctuation\">(</span>V<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>num_heads<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>d_k<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>transpose<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>scaled_dot_product_attention<span class=\"token punctuation\">(</span>Q<span class=\"token punctuation\">,</span> K<span class=\"token punctuation\">,</span> V<span class=\"token punctuation\">,</span> mask<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>transpose<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>contiguous<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>d_model<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>W_o<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></code></pre></div>\n<p>지금 하고 있는 STT(Speech-to-Text) 업무도 결국 이때 생긴 관심이 계기가 되었습니다. 음성과 언어 모델을 연결하는 분야로 방향을 잡게 된 것은 GPT-3의 영향이 컸습니다.</p>\n<h2 id=\"돌아보며\">돌아보며</h2>\n<p>2021년 6월의 그 순간이 일종의 전환점이었다고 생각합니다. \"AI가 정말 뭔가 다르게 될 수 있겠구나\"라는 느낌을 처음 받았던 때였습니다. 물론 그때는 이렇게까지 빨리 발전할 줄은 예상하지 못했습니다.</p>\n<p>GPT-3를 처음 봤을 때 \"대단하다\"고 생각했는데, 지금 돌아보면 그것은 정말 시작에 불과했습니다. ChatGPT, GPT-4, 그리고 현재의 수많은 LLM들을 보면, 2021년의 GPT-3는 새로운 시대의 서막이었던 것 같습니다.</p>\n<h2 id=\"참고-자료\">참고 자료</h2>\n<ul>\n<li><a href=\"https://arxiv.org/abs/2005.14165\">Language Models are Few-Shot Learners</a> - GPT-3 논문</li>\n<li><a href=\"https://platform.openai.com/docs\">OpenAI API Documentation</a> - API 문서</li>\n<li><a href=\"https://arxiv.org/abs/2108.07258\">On the Opportunities and Risks of Foundation Models</a> - Stanford의 Foundation Model 리포트</li>\n</ul>","excerpt":"GPT-3 API를 처음 써본 날 2021년 6월, OpenAI가 GPT-3 API를 공개했습니다. 회사 슬랙에 누군가 공유한 링크를 보고, 저도 바로 API 접근 신청을 했습니다. 며칠 후 승인 메일을 받았을 때의 설렘이 아직도 기억납니다. 처음 API를 호출했을 때 API 키를 받자마자 터미널을 열고 여러 가지를 테스트해봤습니다. 번역, 요약, 코드 …","frontmatter":{"date":"21.06.01","dateISO":"2021-06-01","description":"2021년 6월, GPT-3 API 공개 직후의 경험과 생각","slug":"/gpt3-transformer-revolution-2021","heroImage":null,"heroImageAlt":null,"tags":["ai"],"title":"GPT-3 API를 처음 써본 날"},"tableOfContents":"<ul>\n<li>\n<p><a href=\"#gpt-3-api%EB%A5%BC-%EC%B2%98%EC%9D%8C-%EC%8D%A8%EB%B3%B8-%EB%82%A0\">GPT-3 API를 처음 써본 날</a></p>\n<ul>\n<li>\n<p><a href=\"#%EC%B2%98%EC%9D%8C-api%EB%A5%BC-%ED%98%B8%EC%B6%9C%ED%96%88%EC%9D%84-%EB%95%8C\">처음 API를 호출했을 때</a></p>\n</li>\n<li>\n<p><a href=\"#few-shot-learning%EC%9D%98-%EC%8B%A0%EB%B9%84\">Few-shot Learning의 신비</a></p>\n</li>\n<li>\n<p><a href=\"#%ED%9A%8C%EC%82%AC%EC%97%90%EC%84%9C%EC%9D%98-%EB%B0%98%EC%9D%91\">회사에서의 반응</a></p>\n</li>\n<li>\n<p><a href=\"#%EC%8B%A4%EC%A0%9C-%EC%97%85%EB%AC%B4%EC%97%90-%EC%A0%81%EC%9A%A9%ED%95%B4%EB%B3%B8-%EA%B2%B0%EA%B3%BC\">실제 업무에 적용해본 결과</a></p>\n<ul>\n<li><a href=\"#%EC%8B%9C%EB%8F%84-1-%EA%B3%A0%EA%B0%9D-%EB%AC%B8%EC%9D%98-%EB%B6%84%EB%A5%98\">시도 1: 고객 문의 분류</a></li>\n<li><a href=\"#%EC%8B%9C%EB%8F%84-2-%EC%BD%94%EB%93%9C-%EC%83%9D%EC%84%B1\">시도 2: 코드 생성</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%EA%B8%B0%EC%88%A0%EC%A0%81%EC%9C%BC%EB%A1%9C-%EB%86%80%EB%9D%BC%EC%9B%A0%EB%8D%98-%EC%A0%90\">기술적으로 놀라웠던 점</a></p>\n</li>\n<li>\n<p><a href=\"#%EB%8B%B9%EC%8B%9C%EC%9D%98-%EC%98%88%EC%B8%A1%EA%B3%BC-%EC%8B%A4%EC%A0%9C\">당시의 예측과 실제</a></p>\n<ul>\n<li><a href=\"#%EB%A7%9E%EC%9D%80-%EC%98%88%EC%B8%A1\">맞은 예측</a></li>\n<li><a href=\"#%ED%8B%80%EB%A6%B0-%EC%98%88%EC%B8%A1\">틀린 예측</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%EA%B0%9C%EC%9D%B8%EC%A0%81%EC%9D%B8-%EC%98%81%ED%96%A5\">개인적인 영향</a></p>\n</li>\n<li>\n<p><a href=\"#%EB%8F%8C%EC%95%84%EB%B3%B4%EB%A9%B0\">돌아보며</a></p>\n</li>\n<li>\n<p><a href=\"#%EC%B0%B8%EA%B3%A0-%EC%9E%90%EB%A3%8C\">참고 자료</a></p>\n</li>\n</ul>\n</li>\n</ul>"}},"pageContext":{"id":"402ba3b1-0e81-5993-8665-7f6c4f1ab692","frontmatter__slug":"/gpt3-transformer-revolution-2021","previous":"/remote-work-productivity-tips","previousTitle":"재택근무 1년, 시행착오와 깨달음","next":"/gpt3-transformer-innovation","nextTitle":"GPT-3가 바꿔놓은 것들"}},"staticQueryHashes":["12962592","3399079524","3470099541","4097432363","76375841"],"slicesMap":{}}