{"componentChunkName":"component---src-templates-post-tsx","path":"/posts/vision-devices-large-models-2023/","result":{"data":{"markdownRemark":{"html":"<h1 id=\"2023년-vision-transformer-정리\">2023년 Vision Transformer 정리</h1>\n<p>Vision Transformer(ViT)가 처음 등장한 지 3년이 지난 2023년, 이 분야는 눈부신 발전을 이루었습니다. CNN의 아성을 위협하던 ViT는 이제 컴퓨터 비전의 주류로 자리잡았습니다. 이 글에서는 2023년 중반 기준으로 ViT 계열의 발전 흐름과 실무 경험을 정리합니다.</p>\n<h2 id=\"vit의-원래-문제점\">ViT의 원래 문제점</h2>\n<p>2020년 Google이 발표한 원조 ViT는 혁신적이었지만, 실무에서 사용하기에는 여러 문제가 있었습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 원조 ViT의 복잡도 문제</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">OriginalViTComplexity</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    Self-Attention의 계산 복잡도: O(n²)\n    n = (H * W) / P²  (패치 수)\n\n    예시: 224x224 이미지, 16x16 패치\n    → n = (224 * 224) / (16 * 16) = 196 패치\n\n    1024x1024 이미지라면?\n    → n = (1024 * 1024) / (16 * 16) = 4096 패치\n    → Attention matrix: 4096 x 4096 = 16M elements\n    → GPU 메모리 폭발\n    \"\"\"</span>\n\n    <span class=\"token decorator annotation punctuation\">@staticmethod</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">memory_usage_estimate</span><span class=\"token punctuation\">(</span>image_size<span class=\"token punctuation\">,</span> patch_size<span class=\"token punctuation\">,</span> batch_size<span class=\"token punctuation\">,</span> hidden_dim<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        num_patches <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>image_size <span class=\"token operator\">//</span> patch_size<span class=\"token punctuation\">)</span> <span class=\"token operator\">**</span> <span class=\"token number\">2</span>\n        <span class=\"token comment\"># Attention matrix memory</span>\n        attention_memory <span class=\"token operator\">=</span> batch_size <span class=\"token operator\">*</span> num_patches <span class=\"token operator\">*</span> num_patches <span class=\"token operator\">*</span> <span class=\"token number\">4</span>  <span class=\"token comment\"># float32</span>\n        <span class=\"token comment\"># Hidden states memory</span>\n        hidden_memory <span class=\"token operator\">=</span> batch_size <span class=\"token operator\">*</span> num_patches <span class=\"token operator\">*</span> hidden_dim <span class=\"token operator\">*</span> <span class=\"token number\">4</span>\n\n        <span class=\"token keyword\">return</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token string\">\"attention_matrix_gb\"</span><span class=\"token punctuation\">:</span> attention_memory <span class=\"token operator\">/</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1024</span><span class=\"token operator\">**</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"hidden_states_gb\"</span><span class=\"token punctuation\">:</span> hidden_memory <span class=\"token operator\">/</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1024</span><span class=\"token operator\">**</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"num_patches\"</span><span class=\"token punctuation\">:</span> num_patches\n        <span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\"># 메모리 사용량 비교</span>\nMEMORY_COMPARISON <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token string\">\"224x224\"</span><span class=\"token punctuation\">:</span> OriginalViTComplexity<span class=\"token punctuation\">.</span>memory_usage_estimate<span class=\"token punctuation\">(</span><span class=\"token number\">224</span><span class=\"token punctuation\">,</span> <span class=\"token number\">16</span><span class=\"token punctuation\">,</span> <span class=\"token number\">32</span><span class=\"token punctuation\">,</span> <span class=\"token number\">768</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"512x512\"</span><span class=\"token punctuation\">:</span> OriginalViTComplexity<span class=\"token punctuation\">.</span>memory_usage_estimate<span class=\"token punctuation\">(</span><span class=\"token number\">512</span><span class=\"token punctuation\">,</span> <span class=\"token number\">16</span><span class=\"token punctuation\">,</span> <span class=\"token number\">32</span><span class=\"token punctuation\">,</span> <span class=\"token number\">768</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"1024x1024\"</span><span class=\"token punctuation\">:</span> OriginalViTComplexity<span class=\"token punctuation\">.</span>memory_usage_estimate<span class=\"token punctuation\">(</span><span class=\"token number\">1024</span><span class=\"token punctuation\">,</span> <span class=\"token number\">16</span><span class=\"token punctuation\">,</span> <span class=\"token number\">32</span><span class=\"token punctuation\">,</span> <span class=\"token number\">768</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\"># 결과:</span>\n<span class=\"token comment\"># 224x224: ~0.05GB attention, 196 patches</span>\n<span class=\"token comment\"># 512x512: ~0.8GB attention, 1024 patches</span>\n<span class=\"token comment\"># 1024x1024: ~13GB attention, 4096 patches (단일 배치도 어려움)</span></code></pre></div>\n<p>고해상도 이미지를 처리하려면 GPU가 여러 대 필요했고, 추론 속도도 느렸습니다. 실용적이지 않았습니다.</p>\n<h2 id=\"swin-transformer-게임-체인저\">Swin Transformer: 게임 체인저</h2>\n<p><a href=\"https://arxiv.org/abs/2103.14030\">Swin Transformer</a>는 이 문제를 우아하게 해결했습니다. 윈도우 단위로 어텐션을 계산해서 복잡도를 O(n)으로 줄였습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> torch\n<span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>nn <span class=\"token keyword\">as</span> nn\n<span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>functional <span class=\"token keyword\">as</span> F\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">WindowAttention</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    Window-based Multi-head Self-Attention (W-MSA)\n\n    핵심 아이디어:\n    - 전체 이미지가 아닌 작은 윈도우 내에서만 어텐션 계산\n    - 복잡도: O(n² * M²) → O(n * M²) where M = window size\n    \"\"\"</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>\n        self<span class=\"token punctuation\">,</span>\n        dim<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">,</span>\n        window_size<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">,</span>\n        num_heads<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">,</span>\n        qkv_bias<span class=\"token punctuation\">:</span> <span class=\"token builtin\">bool</span> <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n        attn_drop<span class=\"token punctuation\">:</span> <span class=\"token builtin\">float</span> <span class=\"token operator\">=</span> <span class=\"token number\">0.</span><span class=\"token punctuation\">,</span>\n        proj_drop<span class=\"token punctuation\">:</span> <span class=\"token builtin\">float</span> <span class=\"token operator\">=</span> <span class=\"token number\">0.</span>\n    <span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>dim <span class=\"token operator\">=</span> dim\n        self<span class=\"token punctuation\">.</span>window_size <span class=\"token operator\">=</span> window_size\n        self<span class=\"token punctuation\">.</span>num_heads <span class=\"token operator\">=</span> num_heads\n        head_dim <span class=\"token operator\">=</span> dim <span class=\"token operator\">//</span> num_heads\n        self<span class=\"token punctuation\">.</span>scale <span class=\"token operator\">=</span> head_dim <span class=\"token operator\">**</span> <span class=\"token operator\">-</span><span class=\"token number\">0.5</span>\n\n        <span class=\"token comment\"># Relative position bias</span>\n        self<span class=\"token punctuation\">.</span>relative_position_bias_table <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Parameter<span class=\"token punctuation\">(</span>\n            torch<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span> <span class=\"token operator\">*</span> window_size <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token punctuation\">(</span><span class=\"token number\">2</span> <span class=\"token operator\">*</span> window_size <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> num_heads<span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># QKV projection</span>\n        self<span class=\"token punctuation\">.</span>qkv <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>dim<span class=\"token punctuation\">,</span> dim <span class=\"token operator\">*</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span>qkv_bias<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>attn_drop <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span>attn_drop<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>proj <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>dim<span class=\"token punctuation\">,</span> dim<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>proj_drop <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span>proj_drop<span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># Initialize relative position bias</span>\n        coords_h <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span>window_size<span class=\"token punctuation\">)</span>\n        coords_w <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span>window_size<span class=\"token punctuation\">)</span>\n        coords <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>stack<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>meshgrid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>coords_h<span class=\"token punctuation\">,</span> coords_w<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> indexing<span class=\"token operator\">=</span><span class=\"token string\">'ij'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        coords_flatten <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>flatten<span class=\"token punctuation\">(</span>coords<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        relative_coords <span class=\"token operator\">=</span> coords_flatten<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">-</span> coords_flatten<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span>\n        relative_coords <span class=\"token operator\">=</span> relative_coords<span class=\"token punctuation\">.</span>permute<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>contiguous<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        relative_coords<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+=</span> window_size <span class=\"token operator\">-</span> <span class=\"token number\">1</span>\n        relative_coords<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+=</span> window_size <span class=\"token operator\">-</span> <span class=\"token number\">1</span>\n        relative_coords<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*=</span> <span class=\"token number\">2</span> <span class=\"token operator\">*</span> window_size <span class=\"token operator\">-</span> <span class=\"token number\">1</span>\n        relative_position_index <span class=\"token operator\">=</span> relative_coords<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>register_buffer<span class=\"token punctuation\">(</span><span class=\"token string\">\"relative_position_index\"</span><span class=\"token punctuation\">,</span> relative_position_index<span class=\"token punctuation\">)</span>\n\n        nn<span class=\"token punctuation\">.</span>init<span class=\"token punctuation\">.</span>trunc_normal_<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>relative_position_bias_table<span class=\"token punctuation\">,</span> std<span class=\"token operator\">=</span><span class=\"token number\">.02</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">,</span> mask<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        B_<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">,</span> C <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>shape\n        qkv <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>qkv<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span>B_<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>num_heads<span class=\"token punctuation\">,</span> C <span class=\"token operator\">//</span> self<span class=\"token punctuation\">.</span>num_heads<span class=\"token punctuation\">)</span>\n        qkv <span class=\"token operator\">=</span> qkv<span class=\"token punctuation\">.</span>permute<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span>\n        q<span class=\"token punctuation\">,</span> k<span class=\"token punctuation\">,</span> v <span class=\"token operator\">=</span> qkv<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> qkv<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> qkv<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span>\n\n        q <span class=\"token operator\">=</span> q <span class=\"token operator\">*</span> self<span class=\"token punctuation\">.</span>scale\n        attn <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>q @ k<span class=\"token punctuation\">.</span>transpose<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># Add relative position bias</span>\n        relative_position_bias <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>relative_position_bias_table<span class=\"token punctuation\">[</span>\n            self<span class=\"token punctuation\">.</span>relative_position_index<span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span>\n            self<span class=\"token punctuation\">.</span>window_size <span class=\"token operator\">*</span> self<span class=\"token punctuation\">.</span>window_size<span class=\"token punctuation\">,</span>\n            self<span class=\"token punctuation\">.</span>window_size <span class=\"token operator\">*</span> self<span class=\"token punctuation\">.</span>window_size<span class=\"token punctuation\">,</span>\n            <span class=\"token operator\">-</span><span class=\"token number\">1</span>\n        <span class=\"token punctuation\">)</span>\n        relative_position_bias <span class=\"token operator\">=</span> relative_position_bias<span class=\"token punctuation\">.</span>permute<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>contiguous<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        attn <span class=\"token operator\">=</span> attn <span class=\"token operator\">+</span> relative_position_bias<span class=\"token punctuation\">.</span>unsqueeze<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">if</span> mask <span class=\"token keyword\">is</span> <span class=\"token keyword\">not</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n            nW <span class=\"token operator\">=</span> mask<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n            attn <span class=\"token operator\">=</span> attn<span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span>B_ <span class=\"token operator\">//</span> nW<span class=\"token punctuation\">,</span> nW<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>num_heads<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span>\n            attn <span class=\"token operator\">=</span> attn <span class=\"token operator\">+</span> mask<span class=\"token punctuation\">.</span>unsqueeze<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>unsqueeze<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n            attn <span class=\"token operator\">=</span> attn<span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>num_heads<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span>\n\n        attn <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>softmax<span class=\"token punctuation\">(</span>attn<span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        attn <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>attn_drop<span class=\"token punctuation\">(</span>attn<span class=\"token punctuation\">)</span>\n\n        x <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>attn @ v<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>transpose<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span>B_<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">,</span> C<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>proj<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>proj_drop<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> x\n\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">ShiftedWindowAttention</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    Shifted Window-based Multi-head Self-Attention (SW-MSA)\n\n    문제: 윈도우 경계를 넘는 정보 전달이 안 됨\n    해결: 윈도우를 shift해서 번갈아가며 적용\n    \"\"\"</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> dim<span class=\"token punctuation\">,</span> window_size<span class=\"token punctuation\">,</span> shift_size<span class=\"token punctuation\">,</span> num_heads<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>window_size <span class=\"token operator\">=</span> window_size\n        self<span class=\"token punctuation\">.</span>shift_size <span class=\"token operator\">=</span> shift_size\n        self<span class=\"token punctuation\">.</span>attention <span class=\"token operator\">=</span> WindowAttention<span class=\"token punctuation\">(</span>dim<span class=\"token punctuation\">,</span> window_size<span class=\"token punctuation\">,</span> num_heads<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        H<span class=\"token punctuation\">,</span> W <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span>\n\n        <span class=\"token comment\"># Cyclic shift</span>\n        <span class=\"token keyword\">if</span> self<span class=\"token punctuation\">.</span>shift_size <span class=\"token operator\">></span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n            shifted_x <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>roll<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> shifts<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token operator\">-</span>self<span class=\"token punctuation\">.</span>shift_size<span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span>self<span class=\"token punctuation\">.</span>shift_size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> dims<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n            shifted_x <span class=\"token operator\">=</span> x\n\n        <span class=\"token comment\"># Partition into windows</span>\n        x_windows <span class=\"token operator\">=</span> window_partition<span class=\"token punctuation\">(</span>shifted_x<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>window_size<span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># Window attention</span>\n        attn_windows <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>attention<span class=\"token punctuation\">(</span>x_windows<span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># Merge windows</span>\n        shifted_x <span class=\"token operator\">=</span> window_reverse<span class=\"token punctuation\">(</span>attn_windows<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>window_size<span class=\"token punctuation\">,</span> H<span class=\"token punctuation\">,</span> W<span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># Reverse cyclic shift</span>\n        <span class=\"token keyword\">if</span> self<span class=\"token punctuation\">.</span>shift_size <span class=\"token operator\">></span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n            x <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>roll<span class=\"token punctuation\">(</span>shifted_x<span class=\"token punctuation\">,</span> shifts<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>shift_size<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>shift_size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> dims<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n            x <span class=\"token operator\">=</span> shifted_x\n\n        <span class=\"token keyword\">return</span> x\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">window_partition</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> window_size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    이미지를 윈도우로 분할\n\n    Args:\n        x: (B, H, W, C)\n        window_size: int\n\n    Returns:\n        windows: (num_windows*B, window_size, window_size, C)\n    \"\"\"</span>\n    B<span class=\"token punctuation\">,</span> H<span class=\"token punctuation\">,</span> W<span class=\"token punctuation\">,</span> C <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>shape\n    x <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span>B<span class=\"token punctuation\">,</span> H <span class=\"token operator\">//</span> window_size<span class=\"token punctuation\">,</span> window_size<span class=\"token punctuation\">,</span> W <span class=\"token operator\">//</span> window_size<span class=\"token punctuation\">,</span> window_size<span class=\"token punctuation\">,</span> C<span class=\"token punctuation\">)</span>\n    windows <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>permute<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>contiguous<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> window_size<span class=\"token punctuation\">,</span> window_size<span class=\"token punctuation\">,</span> C<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> windows\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">window_reverse</span><span class=\"token punctuation\">(</span>windows<span class=\"token punctuation\">,</span> window_size<span class=\"token punctuation\">,</span> H<span class=\"token punctuation\">,</span> W<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    윈도우를 원래 이미지로 복원\n\n    Args:\n        windows: (num_windows*B, window_size, window_size, C)\n        window_size: int\n        H, W: int\n\n    Returns:\n        x: (B, H, W, C)\n    \"\"\"</span>\n    B <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>windows<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">/</span> <span class=\"token punctuation\">(</span>H <span class=\"token operator\">*</span> W <span class=\"token operator\">/</span> window_size <span class=\"token operator\">/</span> window_size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    x <span class=\"token operator\">=</span> windows<span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span>B<span class=\"token punctuation\">,</span> H <span class=\"token operator\">//</span> window_size<span class=\"token punctuation\">,</span> W <span class=\"token operator\">//</span> window_size<span class=\"token punctuation\">,</span> window_size<span class=\"token punctuation\">,</span> window_size<span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n    x <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>permute<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>contiguous<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span>B<span class=\"token punctuation\">,</span> H<span class=\"token punctuation\">,</span> W<span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> x</code></pre></div>\n<p>Swin Transformer의 계층적 구조도 중요합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">SwinTransformerStage</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    Swin Transformer의 계층적 구조\n\n    Stage 1: H/4 x W/4 (저해상도, 채널 적음)\n    Stage 2: H/8 x W/8 (patch merging)\n    Stage 3: H/16 x W/16\n    Stage 4: H/32 x W/32 (고해상도 특징)\n\n    → CNN의 feature pyramid와 유사한 효과\n    → Object detection, segmentation에 바로 적용 가능\n    \"\"\"</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> dim<span class=\"token punctuation\">,</span> depth<span class=\"token punctuation\">,</span> num_heads<span class=\"token punctuation\">,</span> window_size<span class=\"token punctuation\">,</span> downsample<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>blocks <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>ModuleList<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n            SwinTransformerBlock<span class=\"token punctuation\">(</span>\n                dim<span class=\"token operator\">=</span>dim<span class=\"token punctuation\">,</span>\n                num_heads<span class=\"token operator\">=</span>num_heads<span class=\"token punctuation\">,</span>\n                window_size<span class=\"token operator\">=</span>window_size<span class=\"token punctuation\">,</span>\n                shift_size<span class=\"token operator\">=</span><span class=\"token number\">0</span> <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>i <span class=\"token operator\">%</span> <span class=\"token number\">2</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">else</span> window_size <span class=\"token operator\">//</span> <span class=\"token number\">2</span>\n            <span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>depth<span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># Patch Merging: 2x2 → 1x1, dim → 2*dim</span>\n        <span class=\"token keyword\">if</span> downsample<span class=\"token punctuation\">:</span>\n            self<span class=\"token punctuation\">.</span>downsample <span class=\"token operator\">=</span> PatchMerging<span class=\"token punctuation\">(</span>dim<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n            self<span class=\"token punctuation\">.</span>downsample <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">for</span> block <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>blocks<span class=\"token punctuation\">:</span>\n            x <span class=\"token operator\">=</span> block<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> self<span class=\"token punctuation\">.</span>downsample <span class=\"token keyword\">is</span> <span class=\"token keyword\">not</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n            x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>downsample<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> x\n\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">PatchMerging</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    Patch Merging: 해상도를 절반으로 줄이고 채널을 2배로 늘림\n    → CNN의 strided conv와 유사한 역할\n    \"\"\"</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> dim<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>dim <span class=\"token operator\">=</span> dim\n        self<span class=\"token punctuation\">.</span>reduction <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span><span class=\"token number\">4</span> <span class=\"token operator\">*</span> dim<span class=\"token punctuation\">,</span> <span class=\"token number\">2</span> <span class=\"token operator\">*</span> dim<span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>norm <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>LayerNorm<span class=\"token punctuation\">(</span><span class=\"token number\">4</span> <span class=\"token operator\">*</span> dim<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        B<span class=\"token punctuation\">,</span> H<span class=\"token punctuation\">,</span> W<span class=\"token punctuation\">,</span> C <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>shape\n\n        <span class=\"token comment\"># 2x2 패치를 하나로 합침</span>\n        x0 <span class=\"token operator\">=</span> x<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">:</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">:</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span>\n        x1 <span class=\"token operator\">=</span> x<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">:</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">:</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span>\n        x2 <span class=\"token operator\">=</span> x<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">:</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">:</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span>\n        x3 <span class=\"token operator\">=</span> x<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">:</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">:</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span>\n        x <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>cat<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>x0<span class=\"token punctuation\">,</span> x1<span class=\"token punctuation\">,</span> x2<span class=\"token punctuation\">,</span> x3<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>norm<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>reduction<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">return</span> x</code></pre></div>\n<p>실제로 써보니 기존 ViT 대비 메모리 사용량이 확연히 줄었습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">SWIN_VS_VIT_COMPARISON <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token string\">\"memory_usage_1024x1024\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"ViT-Base\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"Out of Memory (24GB GPU)\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"Swin-Base\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"~8GB\"</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"throughput_224x224\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"ViT-Base\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"~300 img/s\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"Swin-Base\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"~450 img/s\"</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"imagenet_accuracy\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"ViT-Base\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"81.8%\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"Swin-Base\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"83.5%\"</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<h2 id=\"flash-attention\">Flash Attention</h2>\n<p><a href=\"https://arxiv.org/abs/2205.14135\">Flash Attention</a>은 2023년에 널리 사용되기 시작한 기술입니다. 알고리즘 자체가 아니라 메모리 접근 패턴을 최적화한 것입니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> torch\n<span class=\"token keyword\">from</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>functional <span class=\"token keyword\">import</span> scaled_dot_product_attention\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">FlashAttentionDemo</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    Flash Attention의 핵심 아이디어:\n    - GPU HBM(High Bandwidth Memory)과 SRAM의 속도 차이 활용\n    - 전체 attention matrix를 한 번에 계산하지 않고 블록 단위로 처리\n    - I/O 병목을 줄여서 실제 속도 2-4배 향상\n    \"\"\"</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> dim<span class=\"token punctuation\">,</span> num_heads<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>num_heads <span class=\"token operator\">=</span> num_heads\n        self<span class=\"token punctuation\">.</span>head_dim <span class=\"token operator\">=</span> dim <span class=\"token operator\">//</span> num_heads\n        self<span class=\"token punctuation\">.</span>scale <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>head_dim <span class=\"token operator\">**</span> <span class=\"token operator\">-</span><span class=\"token number\">0.5</span>\n\n        self<span class=\"token punctuation\">.</span>qkv <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>dim<span class=\"token punctuation\">,</span> dim <span class=\"token operator\">*</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>proj <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>dim<span class=\"token punctuation\">,</span> dim<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        B<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">,</span> C <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>shape\n\n        <span class=\"token comment\"># QKV 계산</span>\n        qkv <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>qkv<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span>B<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>num_heads<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>head_dim<span class=\"token punctuation\">)</span>\n        qkv <span class=\"token operator\">=</span> qkv<span class=\"token punctuation\">.</span>permute<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span>\n        q<span class=\"token punctuation\">,</span> k<span class=\"token punctuation\">,</span> v <span class=\"token operator\">=</span> qkv<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> qkv<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> qkv<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span>\n\n        <span class=\"token comment\"># PyTorch 2.0+ Flash Attention (자동 적용)</span>\n        <span class=\"token comment\"># is_causal=False for non-autoregressive models</span>\n        out <span class=\"token operator\">=</span> scaled_dot_product_attention<span class=\"token punctuation\">(</span>\n            q<span class=\"token punctuation\">,</span> k<span class=\"token punctuation\">,</span> v<span class=\"token punctuation\">,</span>\n            attn_mask<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span>\n            dropout_p<span class=\"token operator\">=</span><span class=\"token number\">0.0</span><span class=\"token punctuation\">,</span>\n            is_causal<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span>\n            scale<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>scale\n        <span class=\"token punctuation\">)</span>\n\n        out <span class=\"token operator\">=</span> out<span class=\"token punctuation\">.</span>transpose<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span>B<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">,</span> C<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>proj<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n\n\n<span class=\"token comment\"># Flash Attention 사용 가능 여부 확인</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">check_flash_attention_available</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"PyTorch 2.0+ 에서 Flash Attention 지원 확인\"\"\"</span>\n    <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> torch<span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">.</span>is_available<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token boolean\">False</span>\n\n    <span class=\"token comment\"># CUDA capability check</span>\n    device <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">.</span>current_device<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    capability <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">.</span>get_device_capability<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Flash Attention requires SM80+ (Ampere or newer)</span>\n    <span class=\"token keyword\">if</span> capability<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">>=</span> <span class=\"token number\">8</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token boolean\">True</span>\n\n    <span class=\"token comment\"># FlashAttention-2 on older GPUs via xformers</span>\n    <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">import</span> xformers\n        <span class=\"token keyword\">return</span> <span class=\"token boolean\">True</span>\n    <span class=\"token keyword\">except</span> ImportError<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token boolean\">False</span>\n\n    <span class=\"token keyword\">return</span> <span class=\"token boolean\">False</span>\n\n\n<span class=\"token comment\"># 성능 비교 테스트</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">benchmark_attention</span><span class=\"token punctuation\">(</span>seq_len<span class=\"token operator\">=</span><span class=\"token number\">4096</span><span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token number\">768</span><span class=\"token punctuation\">,</span> num_heads<span class=\"token operator\">=</span><span class=\"token number\">12</span><span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span><span class=\"token number\">8</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"Standard vs Flash Attention 벤치마크\"\"\"</span>\n    <span class=\"token keyword\">import</span> time\n\n    device <span class=\"token operator\">=</span> <span class=\"token string\">\"cuda\"</span>\n    x <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>randn<span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span> seq_len<span class=\"token punctuation\">,</span> dim<span class=\"token punctuation\">,</span> device<span class=\"token operator\">=</span>device<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Standard Attention</span>\n    standard_attn <span class=\"token operator\">=</span> StandardAttention<span class=\"token punctuation\">(</span>dim<span class=\"token punctuation\">,</span> num_heads<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Flash Attention</span>\n    flash_attn <span class=\"token operator\">=</span> FlashAttentionDemo<span class=\"token punctuation\">(</span>dim<span class=\"token punctuation\">,</span> num_heads<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Warmup</span>\n    <span class=\"token keyword\">for</span> _ <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        _ <span class=\"token operator\">=</span> standard_attn<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        _ <span class=\"token operator\">=</span> flash_attn<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n\n    torch<span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">.</span>synchronize<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Standard Attention timing</span>\n    start <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span> _ <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        _ <span class=\"token operator\">=</span> standard_attn<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n    torch<span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">.</span>synchronize<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    standard_time <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> start\n\n    <span class=\"token comment\"># Flash Attention timing</span>\n    start <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span> _ <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        _ <span class=\"token operator\">=</span> flash_attn<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n    torch<span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">.</span>synchronize<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    flash_time <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> start\n\n    <span class=\"token keyword\">return</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"standard_attention_ms\"</span><span class=\"token punctuation\">:</span> standard_time <span class=\"token operator\">*</span> <span class=\"token number\">10</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"flash_attention_ms\"</span><span class=\"token punctuation\">:</span> flash_time <span class=\"token operator\">*</span> <span class=\"token number\">10</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"speedup\"</span><span class=\"token punctuation\">:</span> standard_time <span class=\"token operator\">/</span> flash_time\n    <span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\"># 실제 측정 결과 (A100 GPU)</span>\nBENCHMARK_RESULTS <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token string\">\"seq_len_1024\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span><span class=\"token string\">\"standard\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"12ms\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"flash\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"4ms\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"speedup\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"3x\"</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"seq_len_4096\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span><span class=\"token string\">\"standard\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"180ms\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"flash\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"45ms\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"speedup\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"4x\"</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"seq_len_8192\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span><span class=\"token string\">\"standard\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"OOM\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"flash\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"160ms\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"speedup\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"∞\"</span><span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<p>Flash Attention을 적용하면 코드 한 줄만 바꿔도 학습 속도가 2배 이상 빨라집니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 기존 코드 (PyTorch 1.x)</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">attention_v1</span><span class=\"token punctuation\">(</span>q<span class=\"token punctuation\">,</span> k<span class=\"token punctuation\">,</span> v<span class=\"token punctuation\">,</span> scale<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    attn <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>matmul<span class=\"token punctuation\">(</span>q<span class=\"token punctuation\">,</span> k<span class=\"token punctuation\">.</span>transpose<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> scale\n    attn <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>softmax<span class=\"token punctuation\">(</span>attn<span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n    out <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>matmul<span class=\"token punctuation\">(</span>attn<span class=\"token punctuation\">,</span> v<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> out\n\n<span class=\"token comment\"># Flash Attention 적용 (PyTorch 2.0+)</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">attention_v2</span><span class=\"token punctuation\">(</span>q<span class=\"token punctuation\">,</span> k<span class=\"token punctuation\">,</span> v<span class=\"token punctuation\">,</span> scale<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> F<span class=\"token punctuation\">.</span>scaled_dot_product_attention<span class=\"token punctuation\">(</span>q<span class=\"token punctuation\">,</span> k<span class=\"token punctuation\">,</span> v<span class=\"token punctuation\">,</span> scale<span class=\"token operator\">=</span>scale<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 이게 전부입니다!</span></code></pre></div>\n<h2 id=\"멀티모달-통합-clip과-그-이후\">멀티모달 통합: CLIP과 그 이후</h2>\n<p><a href=\"https://openai.com/research/clip\">CLIP</a>은 텍스트와 이미지를 같은 임베딩 공간에 매핑한다는 간단한 아이디어로 판도를 바꿨습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> torch\n<span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>nn <span class=\"token keyword\">as</span> nn\n<span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>functional <span class=\"token keyword\">as</span> F\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">CLIPLike</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    CLIP의 핵심 구조 재현\n\n    이미지 인코더: ViT\n    텍스트 인코더: Transformer\n    학습: Contrastive Learning (대조 학습)\n    \"\"\"</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>\n        self<span class=\"token punctuation\">,</span>\n        embed_dim<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span> <span class=\"token operator\">=</span> <span class=\"token number\">512</span><span class=\"token punctuation\">,</span>\n        image_encoder<span class=\"token punctuation\">:</span> nn<span class=\"token punctuation\">.</span>Module <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span>\n        text_encoder<span class=\"token punctuation\">:</span> nn<span class=\"token punctuation\">.</span>Module <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span>\n        temperature<span class=\"token punctuation\">:</span> <span class=\"token builtin\">float</span> <span class=\"token operator\">=</span> <span class=\"token number\">0.07</span>\n    <span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>image_encoder <span class=\"token operator\">=</span> image_encoder\n        self<span class=\"token punctuation\">.</span>text_encoder <span class=\"token operator\">=</span> text_encoder\n        self<span class=\"token punctuation\">.</span>temperature <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Parameter<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>ones<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> temperature<span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># Projection heads</span>\n        self<span class=\"token punctuation\">.</span>image_projection <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>embed_dim<span class=\"token punctuation\">,</span> embed_dim<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>text_projection <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>embed_dim<span class=\"token punctuation\">,</span> embed_dim<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">encode_image</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> image<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        features <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>image_encoder<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">)</span>\n        features <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>image_projection<span class=\"token punctuation\">(</span>features<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> F<span class=\"token punctuation\">.</span>normalize<span class=\"token punctuation\">(</span>features<span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">encode_text</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        features <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>text_encoder<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span>\n        features <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>text_projection<span class=\"token punctuation\">(</span>features<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> F<span class=\"token punctuation\">.</span>normalize<span class=\"token punctuation\">(</span>features<span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> image<span class=\"token punctuation\">,</span> text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        image_features <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>encode_image<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">)</span>\n        text_features <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>encode_text<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># Cosine similarity as logits</span>\n        logits_per_image <span class=\"token operator\">=</span> image_features @ text_features<span class=\"token punctuation\">.</span>t<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> self<span class=\"token punctuation\">.</span>temperature\n        logits_per_text <span class=\"token operator\">=</span> logits_per_image<span class=\"token punctuation\">.</span>t<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">return</span> logits_per_image<span class=\"token punctuation\">,</span> logits_per_text\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">contrastive_loss</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> image<span class=\"token punctuation\">,</span> text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token triple-quoted-string string\">\"\"\"\n        InfoNCE Loss (Contrastive Loss)\n\n        목표: 매칭되는 이미지-텍스트 쌍의 유사도를 높이고,\n              매칭되지 않는 쌍의 유사도를 낮춤\n        \"\"\"</span>\n        logits_per_image<span class=\"token punctuation\">,</span> logits_per_text <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>forward<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> text<span class=\"token punctuation\">)</span>\n\n        batch_size <span class=\"token operator\">=</span> image<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n        labels <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span> device<span class=\"token operator\">=</span>image<span class=\"token punctuation\">.</span>device<span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># 대칭적 cross entropy loss</span>\n        loss_i2t <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>cross_entropy<span class=\"token punctuation\">(</span>logits_per_image<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">)</span>\n        loss_t2i <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>cross_entropy<span class=\"token punctuation\">(</span>logits_per_text<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">return</span> <span class=\"token punctuation\">(</span>loss_i2t <span class=\"token operator\">+</span> loss_t2i<span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> <span class=\"token number\">2</span>\n\n\n<span class=\"token comment\"># CLIP 활용 예시: Zero-shot Classification</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">CLIPClassifier</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    학습 없이 새로운 클래스 분류 가능\n    \"\"\"</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> clip_model<span class=\"token punctuation\">,</span> class_names<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>model <span class=\"token operator\">=</span> clip_model\n        self<span class=\"token punctuation\">.</span>class_names <span class=\"token operator\">=</span> class_names\n\n        <span class=\"token comment\"># 클래스별 텍스트 임베딩 미리 계산</span>\n        text_prompts <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"a photo of a </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>name<span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span> <span class=\"token keyword\">for</span> name <span class=\"token keyword\">in</span> class_names<span class=\"token punctuation\">]</span>\n        self<span class=\"token punctuation\">.</span>text_features <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>model<span class=\"token punctuation\">.</span>encode_text<span class=\"token punctuation\">(</span>text_prompts<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">classify</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> image<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        image_features <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>model<span class=\"token punctuation\">.</span>encode_image<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># 코사인 유사도 계산</span>\n        similarities <span class=\"token operator\">=</span> image_features @ self<span class=\"token punctuation\">.</span>text_features<span class=\"token punctuation\">.</span>t<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># 가장 유사한 클래스 반환</span>\n        probs <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>softmax<span class=\"token punctuation\">(</span>similarities<span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        predicted_class <span class=\"token operator\">=</span> probs<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>dim<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>class_names<span class=\"token punctuation\">[</span>predicted_class<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> probs<span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token comment\"># 실제 사용 예시</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">zero_shot_classification_demo</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    CLIP의 Zero-shot 능력 데모\n\n    놀라운 점:\n    - 학습 데이터에 없던 클래스도 분류 가능\n    - 프롬프트만 바꾸면 다른 태스크 수행 가능\n    \"\"\"</span>\n    <span class=\"token comment\"># ImageNet에 없는 클래스들</span>\n    custom_classes <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>\n        <span class=\"token string\">\"a corgi dog\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"a persian cat\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"a grilled cheese sandwich\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"the Eiffel Tower\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"a person riding a bicycle\"</span>\n    <span class=\"token punctuation\">]</span>\n\n    classifier <span class=\"token operator\">=</span> CLIPClassifier<span class=\"token punctuation\">(</span>clip_model<span class=\"token punctuation\">,</span> custom_classes<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># 이미지 분류</span>\n    result<span class=\"token punctuation\">,</span> confidence <span class=\"token operator\">=</span> classifier<span class=\"token punctuation\">.</span>classify<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"Predicted: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>result<span class=\"token punctuation\">}</span></span><span class=\"token string\"> (confidence: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>confidence<span class=\"token punctuation\">:</span><span class=\"token format-spec\">.2%</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">)\"</span></span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>CLIP을 기반으로 한 다양한 응용이 등장했습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">CLIP_BASED_APPLICATIONS <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token string\">\"DALL-E\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"description\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"텍스트에서 이미지 생성\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"how\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"CLIP으로 텍스트-이미지 정합성 평가\"</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"Stable Diffusion\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"description\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"오픈소스 이미지 생성\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"how\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"CLIP text encoder를 조건으로 사용\"</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"BLIP / BLIP-2\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"description\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"이미지 캡셔닝, VQA\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"how\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"CLIP 구조 확장 + 언어 모델\"</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"OpenCLIP\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"description\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"CLIP의 오픈소스 재현\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"how\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"LAION 데이터셋으로 학습\"</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"SAM (Segment Anything)\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"description\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"범용 이미지 분할\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"how\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"CLIP과 유사한 대규모 사전학습\"</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<h2 id=\"실무에서의-vision-transformer\">실무에서의 Vision Transformer</h2>\n<p>2023년에 느낀 점은 \"효율성\"이 진짜 중요하다는 것입니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 실무 관점의 모델 선택 기준</span>\nMODEL_SELECTION_CRITERIA <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token string\">\"accuracy_first\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"recommendation\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"Swin-Large, ViT-Large\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"use_case\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"오프라인 배치 처리, 정확도가 최우선\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"trade_off\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"속도와 비용 포기\"</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"balanced\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"recommendation\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"Swin-Base, ConvNeXt-Base\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"use_case\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"대부분의 프로덕션 환경\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"trade_off\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"정확도 약간 손해, 합리적인 속도\"</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"speed_first\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"recommendation\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"EfficientNetV2-S, MobileViT\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"use_case\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"실시간 처리, 엣지 디바이스\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"trade_off\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"정확도 손해, 빠른 속도\"</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"edge_device\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"recommendation\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"MobileNetV3, EfficientNet-Lite\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"use_case\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"모바일, IoT\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"trade_off\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"정확도 많이 손해, 낮은 리소스 사용\"</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n\n<span class=\"token comment\"># 실제 프로젝트에서의 선택 과정</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">ModelSelectionProcess</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    실무에서 모델을 선택하는 과정\n    \"\"\"</span>\n\n    <span class=\"token decorator annotation punctuation\">@staticmethod</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">analyze_requirements</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token string\">\"latency_requirement\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"&lt; 50ms\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"accuracy_requirement\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"> 85% top-1\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"batch_size\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">32</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"gpu_budget\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"1x V100\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"deployment\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"cloud API\"</span>\n        <span class=\"token punctuation\">}</span>\n\n    <span class=\"token decorator annotation punctuation\">@staticmethod</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">benchmark_candidates</span><span class=\"token punctuation\">(</span>requirements<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        candidates <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>\n            <span class=\"token punctuation\">{</span><span class=\"token string\">\"name\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"ViT-Base\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"latency\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"35ms\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"accuracy\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"81.8%\"</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n            <span class=\"token punctuation\">{</span><span class=\"token string\">\"name\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"Swin-Base\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"latency\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"28ms\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"accuracy\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"83.5%\"</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n            <span class=\"token punctuation\">{</span><span class=\"token string\">\"name\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"ConvNeXt-Base\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"latency\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"25ms\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"accuracy\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"83.8%\"</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n            <span class=\"token punctuation\">{</span><span class=\"token string\">\"name\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"EfficientNetV2-M\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"latency\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"15ms\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"accuracy\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"85.1%\"</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token punctuation\">]</span>\n\n        <span class=\"token comment\"># 요구사항 만족 여부 확인</span>\n        suitable <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">for</span> c <span class=\"token keyword\">in</span> candidates<span class=\"token punctuation\">:</span>\n            latency_ok <span class=\"token operator\">=</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">[</span><span class=\"token string\">\"latency\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">\"ms\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span> <span class=\"token number\">50</span>\n            accuracy_ok <span class=\"token operator\">=</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">[</span><span class=\"token string\">\"accuracy\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">\"%\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">></span> <span class=\"token number\">85</span>\n\n            <span class=\"token keyword\">if</span> latency_ok <span class=\"token keyword\">and</span> accuracy_ok<span class=\"token punctuation\">:</span>\n                suitable<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">return</span> suitable  <span class=\"token comment\"># EfficientNetV2-M만 둘 다 만족</span>\n\n    <span class=\"token decorator annotation punctuation\">@staticmethod</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">final_decision</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token triple-quoted-string string\">\"\"\"\n        최종 결정 시 고려사항\n        \"\"\"</span>\n        <span class=\"token keyword\">return</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token string\">\"selected\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"EfficientNetV2-M\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"reasons\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span>\n                <span class=\"token string\">\"요구 정확도 만족 (85.1%)\"</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">\"요구 지연시간 만족 (15ms)\"</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">\"학습 코드/체크포인트 풍부\"</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">\"커뮤니티 지원 활발\"</span>\n            <span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"alternatives_considered\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span>\n                <span class=\"token string\">\"Swin-Base: 정확도 미달\"</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">\"ConvNeXt-Base: 정확도 미달\"</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">\"ViT-Base: 정확도 미달\"</span>\n            <span class=\"token punctuation\">]</span>\n        <span class=\"token punctuation\">}</span></code></pre></div>\n<h2 id=\"최적화-기법들\">최적화 기법들</h2>\n<p>실제 배포 시 사용한 최적화 기법들입니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> torch\n<span class=\"token keyword\">from</span> torch <span class=\"token keyword\">import</span> nn\n\n<span class=\"token comment\"># 1. Mixed Precision Training</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">train_with_mixed_precision</span><span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">,</span> dataloader<span class=\"token punctuation\">,</span> optimizer<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    scaler <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">.</span>amp<span class=\"token punctuation\">.</span>GradScaler<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">for</span> batch <span class=\"token keyword\">in</span> dataloader<span class=\"token punctuation\">:</span>\n        optimizer<span class=\"token punctuation\">.</span>zero_grad<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># FP16 forward pass</span>\n        <span class=\"token keyword\">with</span> torch<span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">.</span>amp<span class=\"token punctuation\">.</span>autocast<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            outputs <span class=\"token operator\">=</span> model<span class=\"token punctuation\">(</span>batch<span class=\"token punctuation\">[</span><span class=\"token string\">\"image\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n            loss <span class=\"token operator\">=</span> criterion<span class=\"token punctuation\">(</span>outputs<span class=\"token punctuation\">,</span> batch<span class=\"token punctuation\">[</span><span class=\"token string\">\"label\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># Scaled backward pass</span>\n        scaler<span class=\"token punctuation\">.</span>scale<span class=\"token punctuation\">(</span>loss<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>backward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        scaler<span class=\"token punctuation\">.</span>step<span class=\"token punctuation\">(</span>optimizer<span class=\"token punctuation\">)</span>\n        scaler<span class=\"token punctuation\">.</span>update<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token comment\"># 2. Torch Compile (PyTorch 2.0+)</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">optimize_with_compile</span><span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    PyTorch 2.0의 torch.compile로 자동 최적화\n    - 커널 퓨전\n    - 메모리 최적화\n    - GPU 활용 최적화\n    \"\"\"</span>\n    optimized_model <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>\n        model<span class=\"token punctuation\">,</span>\n        mode<span class=\"token operator\">=</span><span class=\"token string\">\"reduce-overhead\"</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># 또는 \"max-autotune\"</span>\n        fullgraph<span class=\"token operator\">=</span><span class=\"token boolean\">True</span>\n    <span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> optimized_model\n\n\n<span class=\"token comment\"># 3. ONNX 변환 및 최적화</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">export_to_onnx</span><span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">,</span> input_shape<span class=\"token punctuation\">,</span> output_path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    ONNX로 변환하여 다양한 런타임에서 사용\n    \"\"\"</span>\n    <span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>onnx\n\n    dummy_input <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>randn<span class=\"token punctuation\">(</span><span class=\"token operator\">*</span>input_shape<span class=\"token punctuation\">)</span>\n\n    torch<span class=\"token punctuation\">.</span>onnx<span class=\"token punctuation\">.</span>export<span class=\"token punctuation\">(</span>\n        model<span class=\"token punctuation\">,</span>\n        dummy_input<span class=\"token punctuation\">,</span>\n        output_path<span class=\"token punctuation\">,</span>\n        export_params<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n        opset_version<span class=\"token operator\">=</span><span class=\"token number\">17</span><span class=\"token punctuation\">,</span>\n        do_constant_folding<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n        input_names<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'input'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n        output_names<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'output'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n        dynamic_axes<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span>\n            <span class=\"token string\">'input'</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span><span class=\"token number\">0</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'batch_size'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">'output'</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span><span class=\"token number\">0</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'batch_size'</span><span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">)</span>\n\n\n<span class=\"token comment\"># 4. TensorRT 최적화</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">optimize_with_tensorrt</span><span class=\"token punctuation\">(</span>onnx_path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    TensorRT로 추론 최적화 (NVIDIA GPU)\n    \"\"\"</span>\n    <span class=\"token keyword\">import</span> tensorrt <span class=\"token keyword\">as</span> trt\n\n    logger <span class=\"token operator\">=</span> trt<span class=\"token punctuation\">.</span>Logger<span class=\"token punctuation\">(</span>trt<span class=\"token punctuation\">.</span>Logger<span class=\"token punctuation\">.</span>WARNING<span class=\"token punctuation\">)</span>\n    builder <span class=\"token operator\">=</span> trt<span class=\"token punctuation\">.</span>Builder<span class=\"token punctuation\">(</span>logger<span class=\"token punctuation\">)</span>\n    network <span class=\"token operator\">=</span> builder<span class=\"token punctuation\">.</span>create_network<span class=\"token punctuation\">(</span>\n        <span class=\"token number\">1</span> <span class=\"token operator\">&lt;&lt;</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>trt<span class=\"token punctuation\">.</span>NetworkDefinitionCreationFlag<span class=\"token punctuation\">.</span>EXPLICIT_BATCH<span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">)</span>\n    parser <span class=\"token operator\">=</span> trt<span class=\"token punctuation\">.</span>OnnxParser<span class=\"token punctuation\">(</span>network<span class=\"token punctuation\">,</span> logger<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>onnx_path<span class=\"token punctuation\">,</span> <span class=\"token string\">'rb'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span>\n        parser<span class=\"token punctuation\">.</span>parse<span class=\"token punctuation\">(</span>f<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    config <span class=\"token operator\">=</span> builder<span class=\"token punctuation\">.</span>create_builder_config<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    config<span class=\"token punctuation\">.</span>set_memory_pool_limit<span class=\"token punctuation\">(</span>trt<span class=\"token punctuation\">.</span>MemoryPoolType<span class=\"token punctuation\">.</span>WORKSPACE<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span> <span class=\"token operator\">&lt;&lt;</span> <span class=\"token number\">30</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># FP16 최적화</span>\n    <span class=\"token keyword\">if</span> builder<span class=\"token punctuation\">.</span>platform_has_fast_fp16<span class=\"token punctuation\">:</span>\n        config<span class=\"token punctuation\">.</span>set_flag<span class=\"token punctuation\">(</span>trt<span class=\"token punctuation\">.</span>BuilderFlag<span class=\"token punctuation\">.</span>FP16<span class=\"token punctuation\">)</span>\n\n    engine <span class=\"token operator\">=</span> builder<span class=\"token punctuation\">.</span>build_serialized_network<span class=\"token punctuation\">(</span>network<span class=\"token punctuation\">,</span> config<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> engine\n\n\n<span class=\"token comment\"># 최적화 효과 비교</span>\nOPTIMIZATION_RESULTS <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token string\">\"Swin-Base (224x224, batch=32)\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"baseline_pytorch\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"45ms\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"mixed_precision\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"28ms (1.6x)\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"torch_compile\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"22ms (2.0x)\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"tensorrt_fp16\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"12ms (3.8x)\"</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<h2 id=\"2024년-전망\">2024년 전망</h2>\n<p>더 효율적인 아키텍처가 계속 나올 것입니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">FUTURE_TRENDS <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token string\">\"efficient_architectures\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"description\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"더 작고 빠른 모델\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"examples\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"EfficientViT\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"FastViT\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"MobileViT v2\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"target\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"엣지 디바이스에서 ViT 성능\"</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"foundation_models\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"description\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"대규모 사전학습 모델\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"examples\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"DINOv2\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"SAM\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"ImageBind\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"impact\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"다운스트림 태스크 성능 향상\"</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"multimodal_expansion\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"description\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"비전을 넘어선 통합\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"examples\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"GPT-4V\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Gemini\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"LLaVA\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"direction\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"Vision + Language + Audio 통합\"</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"hardware_codesign\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"description\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"하드웨어와 함께 설계\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"examples\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"Apple Neural Engine 최적화 모델\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"goal\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"특정 칩에서 최적 성능\"</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<h2 id=\"참고-자료\">참고 자료</h2>\n<ul>\n<li><a href=\"https://arxiv.org/abs/2010.11929\">An Image is Worth 16x16 Words (ViT)</a></li>\n<li><a href=\"https://arxiv.org/abs/2103.14030\">Swin Transformer</a></li>\n<li><a href=\"https://arxiv.org/abs/2205.14135\">Flash Attention</a></li>\n<li><a href=\"https://arxiv.org/abs/2103.00020\">CLIP</a></li>\n<li><a href=\"https://arxiv.org/abs/2201.03545\">ConvNeXt</a></li>\n<li><a href=\"https://github.com/huggingface/pytorch-image-models\">timm library</a> - 다양한 비전 모델 구현</li>\n</ul>","excerpt":"2023년 Vision Transformer 정리 Vision Transformer(ViT)가 처음 등장한 지 3년이 지난 2023년, 이 분야는 눈부신 발전을 이루었습니다. CNN의 아성을 위협하던 ViT는 이제 컴퓨터 비전의 주류로 자리잡았습니다. 이 글에서는 2023년 중반 기준으로 ViT 계열의 발전 흐름과 실무 경험을 정리합니다. ViT의 원래 …","frontmatter":{"date":"23.07.01","dateISO":"2023-07-01","description":"Vision Transformer 3년의 발전사 - ViT의 O(n²) 복잡도 문제부터 Swin Transformer, DINOv2까지 실무 관점에서 정리한 2023년 컴퓨터 비전 트렌드","slug":"/vision-devices-large-models-2023","heroImage":null,"heroImageAlt":null,"tags":["ai"],"title":"2023년 Vision Transformer 정리"},"tableOfContents":"<ul>\n<li>\n<p><a href=\"#2023%EB%85%84-vision-transformer-%EC%A0%95%EB%A6%AC\">2023년 Vision Transformer 정리</a></p>\n<ul>\n<li><a href=\"#vit%EC%9D%98-%EC%9B%90%EB%9E%98-%EB%AC%B8%EC%A0%9C%EC%A0%90\">ViT의 원래 문제점</a></li>\n<li><a href=\"#swin-transformer-%EA%B2%8C%EC%9E%84-%EC%B2%B4%EC%9D%B8%EC%A0%80\">Swin Transformer: 게임 체인저</a></li>\n<li><a href=\"#flash-attention\">Flash Attention</a></li>\n<li><a href=\"#%EB%A9%80%ED%8B%B0%EB%AA%A8%EB%8B%AC-%ED%86%B5%ED%95%A9-clip%EA%B3%BC-%EA%B7%B8-%EC%9D%B4%ED%9B%84\">멀티모달 통합: CLIP과 그 이후</a></li>\n<li><a href=\"#%EC%8B%A4%EB%AC%B4%EC%97%90%EC%84%9C%EC%9D%98-vision-transformer\">실무에서의 Vision Transformer</a></li>\n<li><a href=\"#%EC%B5%9C%EC%A0%81%ED%99%94-%EA%B8%B0%EB%B2%95%EB%93%A4\">최적화 기법들</a></li>\n<li><a href=\"#2024%EB%85%84-%EC%A0%84%EB%A7%9D\">2024년 전망</a></li>\n<li><a href=\"#%EC%B0%B8%EA%B3%A0-%EC%9E%90%EB%A3%8C\">참고 자료</a></li>\n</ul>\n</li>\n</ul>"}},"pageContext":{"id":"12721993-9755-54b5-b2aa-ca5a2d80a07d","frontmatter__slug":"/vision-devices-large-models-2023","previous":"/llama-opensource-ecosystem-2023","previousTitle":"LLaMA가 바꿔놓은 것들","next":"/mobile-ai-optimization-2023","nextTitle":"모바일에서 AI 모델 돌리기"}},"staticQueryHashes":["12962592","3399079524","3470099541","4097432363","76375841"],"slicesMap":{}}