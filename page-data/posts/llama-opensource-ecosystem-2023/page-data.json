{"componentChunkName":"component---src-templates-post-tsx","path":"/posts/llama-opensource-ecosystem-2023/","result":{"data":{"markdownRemark":{"html":"<h1 id=\"llama가-바꿔놓은-것들\">LLaMA가 바꿔놓은 것들</h1>\n<p>2023년 2월, Meta가 <a href=\"https://arxiv.org/abs/2302.13971\">LLaMA</a>를 공개했습니다. 처음에는 \"그래서 뭐가 달라지나?\"라고 생각했는데, 돌이켜보면 이 모델이 오픈소스 LLM 생태계의 판을 완전히 바꿔놓았습니다. 이 글에서는 2023년 한 해 동안 일어난 변화와 실제 경험을 정리합니다.</p>\n<h2 id=\"llama-공개-전과-후\">LLaMA 공개 전과 후</h2>\n<h3 id=\"공개-전-api-종속의-시대\">공개 전: API 종속의 시대</h3>\n<p>LLaMA 이전에는 대형 언어 모델을 사용하는 방법이 제한적이었습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 2023년 초반의 LLM 사용 방식</span>\nLLM_OPTIONS_BEFORE_LLAMA <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token string\">\"OpenAI API\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"models\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"GPT-3.5\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"GPT-4\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"pros\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"높은 성능\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"쉬운 사용\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"cons\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"비용\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"프라이버시\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"커스터마이징 불가\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"종속성\"</span><span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"Cohere / Anthropic API\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"models\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"Command\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Claude\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"pros\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"대안 존재\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"cons\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"동일한 한계\"</span><span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"오픈소스 (GPT-J, GPT-Neo)\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"models\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"GPT-J-6B\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"GPT-NeoX-20B\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"pros\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"오픈소스\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"자체 운영 가능\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"cons\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"성능 부족\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"상용 모델과 큰 격차\"</span><span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\"># 당시 상황: GPT-4가 나오면 감탄만 하고 끝</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">typical_workflow_2022</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># 1. OpenAI API 호출</span>\n    response <span class=\"token operator\">=</span> openai<span class=\"token punctuation\">.</span>ChatCompletion<span class=\"token punctuation\">.</span>create<span class=\"token punctuation\">(</span>\n        model<span class=\"token operator\">=</span><span class=\"token string\">\"gpt-4\"</span><span class=\"token punctuation\">,</span>\n        messages<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">{</span><span class=\"token string\">\"role\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"user\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"content\"</span><span class=\"token punctuation\">:</span> prompt<span class=\"token punctuation\">}</span><span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># 2. 비용 걱정</span>\n    cost <span class=\"token operator\">=</span> calculate_cost<span class=\"token punctuation\">(</span>response<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 토큰당 과금</span>\n\n    <span class=\"token comment\"># 3. 프라이버시 우려</span>\n    <span class=\"token comment\"># \"민감한 데이터를 외부 서버로 보내도 되나?\"</span>\n\n    <span class=\"token comment\"># 4. 커스터마이징 불가</span>\n    <span class=\"token comment\"># \"우리 도메인에 맞게 조정할 수 없다\"</span>\n\n    <span class=\"token keyword\">return</span> response</code></pre></div>\n<h3 id=\"공개-후-새로운-가능성\">공개 후: 새로운 가능성</h3>\n<p>LLaMA는 모델 가중치가 (유출을 통해) 공개되면서 모든 것이 달라졌습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># LLaMA 이후 가능해진 것들</span>\nLLAMA_ENABLED_CAPABILITIES <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token string\">\"로컬 실행\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"description\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"내 컴퓨터에서 LLM 실행\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"benefit\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"API 비용 없음, 프라이버시 보장\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"example\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"llama.cpp로 맥북에서 7B 모델 실행\"</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"파인튜닝\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"description\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"자체 데이터로 모델 조정\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"benefit\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"도메인 특화 모델 제작 가능\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"example\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"의료, 법률, 코드 특화 모델\"</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"연구\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"description\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"모델 내부 분석 가능\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"benefit\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"학문적 연구, 개선 가능\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"example\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"Interpretability 연구\"</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"상업화\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"description\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"LLaMA 2부터 상업적 사용 허용\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"benefit\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"스타트업도 LLM 기반 서비스 가능\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"example\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"자체 챗봇, AI 어시스턴트\"</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<h2 id=\"생태계-폭발\">생태계 폭발</h2>\n<p>LLaMA 공개 후 몇 달 사이에 놀라운 속도로 생태계가 형성되었습니다.</p>\n<h3 id=\"파인튜닝-모델들\">파인튜닝 모델들</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">LLAMA_FINETUNED_MODELS <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token string\">\"Alpaca\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"release\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"2023년 3월\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"creator\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"Stanford\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"method\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"GPT-3.5로 생성한 52K instruction 데이터로 파인튜닝\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"significance\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"저비용 파인튜닝 가능성 입증 ($600 미만)\"</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"Vicuna\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"release\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"2023년 3월\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"creator\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"LMSYS\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"method\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"ShareGPT 대화 데이터로 파인튜닝\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"significance\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"GPT-4 대비 90% 품질 주장\"</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"WizardLM\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"release\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"2023년 4월\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"creator\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"Microsoft\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"method\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"Evol-Instruct로 복잡한 instruction 생성\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"significance\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"복잡한 추론 능력 향상\"</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"Orca\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"release\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"2023년 6월\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"creator\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"Microsoft\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"method\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"GPT-4의 단계별 추론 과정 학습\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"significance\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"작은 모델에서 추론 능력 개선\"</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"CodeLlama\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"release\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"2023년 8월\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"creator\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"Meta\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"method\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"코드 데이터로 추가 학습\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"significance\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"공식 코드 특화 버전\"</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<h3 id=\"효율성-도구들\">효율성 도구들</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># llama.cpp - 가장 영향력 있는 프로젝트 중 하나</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">LlamaCppImpact</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    llama.cpp가 가져온 변화\n\n    핵심: CPU에서 LLaMA 실행 가능\n    → GPU 없이도 LLM 사용 가능\n    → 맥북, 라즈베리파이에서도 실행\n    \"\"\"</span>\n\n    <span class=\"token decorator annotation punctuation\">@staticmethod</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">supported_quantization</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token string\">\"Q4_0\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span><span class=\"token string\">\"bits\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"size_7b\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"3.9GB\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"quality\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"acceptable\"</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"Q4_K_M\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span><span class=\"token string\">\"bits\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"size_7b\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"4.1GB\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"quality\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"good\"</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"Q5_K_M\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span><span class=\"token string\">\"bits\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"size_7b\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"4.8GB\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"quality\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"very good\"</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"Q8_0\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span><span class=\"token string\">\"bits\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">8</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"size_7b\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"7.2GB\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"quality\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"excellent\"</span><span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n\n    <span class=\"token decorator annotation punctuation\">@staticmethod</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">performance_example</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token triple-quoted-string string\">\"\"\"\n        M2 MacBook Pro에서 LLaMA 7B 실행\n        \"\"\"</span>\n        <span class=\"token keyword\">return</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token string\">\"model\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"LLaMA 7B Q4_K_M\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"device\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"M2 Pro (16GB RAM)\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"load_time\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"~3초\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"tokens_per_second\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"~20 tok/s\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"memory_usage\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"~5GB\"</span>\n        <span class=\"token punctuation\">}</span>\n\n\n<span class=\"token comment\"># GGML/GGUF 포맷</span>\nQUANTIZATION_FORMATS <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token string\">\"GGML\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"description\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"초기 llama.cpp 포맷\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"status\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"deprecated\"</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"GGUF\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"description\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"개선된 포맷 (2023년 8월~)\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"features\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"메타데이터 포함\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"확장 가능\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"더 나은 호환성\"</span><span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"GPTQ\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"description\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"GPU 최적화 양자화\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"features\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"4-bit 양자화\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"GPU에서 빠른 추론\"</span><span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"AWQ\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"description\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"Activation-aware 양자화\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"features\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"더 나은 품질\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"GPTQ보다 약간 느림\"</span><span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<h2 id=\"실제로-해본-것들\">실제로 해본 것들</h2>\n<h3 id=\"로컬-llm-실행\">로컬 LLM 실행</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># llama-cpp-python 사용 예시</span>\n<span class=\"token keyword\">from</span> llama_cpp <span class=\"token keyword\">import</span> Llama\n\n<span class=\"token comment\"># 모델 로드 (Q4 양자화 버전)</span>\nllm <span class=\"token operator\">=</span> Llama<span class=\"token punctuation\">(</span>\n    model_path<span class=\"token operator\">=</span><span class=\"token string\">\"./models/llama-2-7b-chat.Q4_K_M.gguf\"</span><span class=\"token punctuation\">,</span>\n    n_ctx<span class=\"token operator\">=</span><span class=\"token number\">4096</span><span class=\"token punctuation\">,</span>        <span class=\"token comment\"># 컨텍스트 길이</span>\n    n_threads<span class=\"token operator\">=</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span>       <span class=\"token comment\"># CPU 스레드 수</span>\n    n_gpu_layers<span class=\"token operator\">=</span><span class=\"token number\">35</span><span class=\"token punctuation\">,</span>   <span class=\"token comment\"># GPU 오프로드 (Metal/CUDA)</span>\n    verbose<span class=\"token operator\">=</span><span class=\"token boolean\">False</span>\n<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 추론</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">generate_response</span><span class=\"token punctuation\">(</span>prompt<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">,</span> max_tokens<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span> <span class=\"token operator\">=</span> <span class=\"token number\">512</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    response <span class=\"token operator\">=</span> llm<span class=\"token punctuation\">(</span>\n        <span class=\"token string-interpolation\"><span class=\"token string\">f\"[INST] </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>prompt<span class=\"token punctuation\">}</span></span><span class=\"token string\"> [/INST]\"</span></span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># LLaMA 2 Chat 포맷</span>\n        max_tokens<span class=\"token operator\">=</span>max_tokens<span class=\"token punctuation\">,</span>\n        temperature<span class=\"token operator\">=</span><span class=\"token number\">0.7</span><span class=\"token punctuation\">,</span>\n        top_p<span class=\"token operator\">=</span><span class=\"token number\">0.95</span><span class=\"token punctuation\">,</span>\n        repeat_penalty<span class=\"token operator\">=</span><span class=\"token number\">1.1</span><span class=\"token punctuation\">,</span>\n        stop<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"[INST]\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"[/INST]\"</span><span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> response<span class=\"token punctuation\">[</span><span class=\"token string\">\"choices\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token comment\"># 사용 예시</span>\nresult <span class=\"token operator\">=</span> generate_response<span class=\"token punctuation\">(</span><span class=\"token string\">\"Python으로 퀵소트를 구현해줘\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>result<span class=\"token punctuation\">)</span></code></pre></div>\n<p>실행 성능 측정 결과입니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">LOCAL_LLM_BENCHMARKS <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token string\">\"M2 Pro MacBook (16GB)\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"LLaMA 7B Q4\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token string\">\"load_time\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"2.8s\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"tokens_per_second\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"22 tok/s\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"first_token_latency\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"0.5s\"</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"LLaMA 13B Q4\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token string\">\"load_time\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"5.2s\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"tokens_per_second\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"12 tok/s\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"first_token_latency\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"1.2s\"</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"RTX 4090 (24GB)\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"LLaMA 7B Q4\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token string\">\"load_time\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"1.5s\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"tokens_per_second\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"95 tok/s\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"first_token_latency\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"0.1s\"</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"LLaMA 13B Q4\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token string\">\"load_time\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"2.8s\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"tokens_per_second\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"55 tok/s\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"first_token_latency\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"0.2s\"</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"LLaMA 70B Q4\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token string\">\"load_time\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"25s\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"tokens_per_second\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"15 tok/s\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"first_token_latency\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"0.8s\"</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<h3 id=\"파인튜닝-시도\">파인튜닝 시도</h3>\n<p>LoRA(Low-Rank Adaptation)를 사용해서 도메인 특화 모델을 학습시켜봤습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> transformers <span class=\"token keyword\">import</span> <span class=\"token punctuation\">(</span>\n    AutoModelForCausalLM<span class=\"token punctuation\">,</span>\n    AutoTokenizer<span class=\"token punctuation\">,</span>\n    TrainingArguments<span class=\"token punctuation\">,</span>\n    Trainer\n<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">from</span> peft <span class=\"token keyword\">import</span> <span class=\"token punctuation\">(</span>\n    LoraConfig<span class=\"token punctuation\">,</span>\n    get_peft_model<span class=\"token punctuation\">,</span>\n    prepare_model_for_kbit_training\n<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">from</span> datasets <span class=\"token keyword\">import</span> load_dataset\n<span class=\"token keyword\">import</span> torch\n\n<span class=\"token comment\"># 모델 로드 (4-bit 양자화)</span>\nmodel <span class=\"token operator\">=</span> AutoModelForCausalLM<span class=\"token punctuation\">.</span>from_pretrained<span class=\"token punctuation\">(</span>\n    <span class=\"token string\">\"meta-llama/Llama-2-7b-hf\"</span><span class=\"token punctuation\">,</span>\n    load_in_4bit<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n    torch_dtype<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span>float16<span class=\"token punctuation\">,</span>\n    device_map<span class=\"token operator\">=</span><span class=\"token string\">\"auto\"</span><span class=\"token punctuation\">,</span>\n    quantization_config<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"load_in_4bit\"</span><span class=\"token punctuation\">:</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"bnb_4bit_compute_dtype\"</span><span class=\"token punctuation\">:</span> torch<span class=\"token punctuation\">.</span>float16<span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"bnb_4bit_quant_type\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"nf4\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"bnb_4bit_use_double_quant\"</span><span class=\"token punctuation\">:</span> <span class=\"token boolean\">True</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">)</span>\n\ntokenizer <span class=\"token operator\">=</span> AutoTokenizer<span class=\"token punctuation\">.</span>from_pretrained<span class=\"token punctuation\">(</span><span class=\"token string\">\"meta-llama/Llama-2-7b-hf\"</span><span class=\"token punctuation\">)</span>\ntokenizer<span class=\"token punctuation\">.</span>pad_token <span class=\"token operator\">=</span> tokenizer<span class=\"token punctuation\">.</span>eos_token\n\n<span class=\"token comment\"># 4-bit 학습 준비</span>\nmodel <span class=\"token operator\">=</span> prepare_model_for_kbit_training<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># LoRA 설정</span>\nlora_config <span class=\"token operator\">=</span> LoraConfig<span class=\"token punctuation\">(</span>\n    r<span class=\"token operator\">=</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span>                      <span class=\"token comment\"># LoRA rank</span>\n    lora_alpha<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span>             <span class=\"token comment\"># 스케일링 파라미터</span>\n    target_modules<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>           <span class=\"token comment\"># 적용할 레이어</span>\n        <span class=\"token string\">\"q_proj\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"k_proj\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"v_proj\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"o_proj\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"gate_proj\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"up_proj\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"down_proj\"</span>\n    <span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n    lora_dropout<span class=\"token operator\">=</span><span class=\"token number\">0.05</span><span class=\"token punctuation\">,</span>\n    bias<span class=\"token operator\">=</span><span class=\"token string\">\"none\"</span><span class=\"token punctuation\">,</span>\n    task_type<span class=\"token operator\">=</span><span class=\"token string\">\"CAUSAL_LM\"</span>\n<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># LoRA 적용</span>\nmodel <span class=\"token operator\">=</span> get_peft_model<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">,</span> lora_config<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 학습 가능한 파라미터 확인</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">print_trainable_parameters</span><span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    trainable <span class=\"token operator\">=</span> <span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>p<span class=\"token punctuation\">.</span>numel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> p <span class=\"token keyword\">in</span> model<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">if</span> p<span class=\"token punctuation\">.</span>requires_grad<span class=\"token punctuation\">)</span>\n    total <span class=\"token operator\">=</span> <span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>p<span class=\"token punctuation\">.</span>numel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> p <span class=\"token keyword\">in</span> model<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"Trainable: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>trainable<span class=\"token punctuation\">:</span><span class=\"token format-spec\">,</span><span class=\"token punctuation\">}</span></span><span class=\"token string\"> / </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>total<span class=\"token punctuation\">:</span><span class=\"token format-spec\">,</span><span class=\"token punctuation\">}</span></span><span class=\"token string\"> (</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span><span class=\"token number\">100</span><span class=\"token operator\">*</span>trainable<span class=\"token operator\">/</span>total<span class=\"token punctuation\">:</span><span class=\"token format-spec\">.2f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">%)\"</span></span><span class=\"token punctuation\">)</span>\n\nprint_trainable_parameters<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># 출력: Trainable: 4,194,304 / 6,742,609,920 (0.06%)</span>\n<span class=\"token comment\"># → 전체 파라미터의 0.06%만 학습!</span></code></pre></div>\n<p>학습 데이터 준비와 실행입니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 데이터셋 준비 (Instruction 포맷)</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">format_instruction</span><span class=\"token punctuation\">(</span>sample<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    LLaMA 2 Instruction 포맷\n    \"\"\"</span>\n    instruction <span class=\"token operator\">=</span> sample<span class=\"token punctuation\">[</span><span class=\"token string\">\"instruction\"</span><span class=\"token punctuation\">]</span>\n    input_text <span class=\"token operator\">=</span> sample<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">\"input\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"\"</span><span class=\"token punctuation\">)</span>\n    output <span class=\"token operator\">=</span> sample<span class=\"token punctuation\">[</span><span class=\"token string\">\"output\"</span><span class=\"token punctuation\">]</span>\n\n    <span class=\"token keyword\">if</span> input_text<span class=\"token punctuation\">:</span>\n        prompt <span class=\"token operator\">=</span> <span class=\"token string-interpolation\"><span class=\"token string\">f\"\"\"[INST] </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>instruction<span class=\"token punctuation\">}</span></span><span class=\"token string\">\n\n</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>input_text<span class=\"token punctuation\">}</span></span><span class=\"token string\"> [/INST] </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>output<span class=\"token punctuation\">}</span></span><span class=\"token string\">\"\"\"</span></span>\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n        prompt <span class=\"token operator\">=</span> <span class=\"token string-interpolation\"><span class=\"token string\">f\"[INST] </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>instruction<span class=\"token punctuation\">}</span></span><span class=\"token string\"> [/INST] </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>output<span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span>\n\n    <span class=\"token keyword\">return</span> <span class=\"token punctuation\">{</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">:</span> prompt<span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\"># 데이터셋 로드 및 포맷팅</span>\ndataset <span class=\"token operator\">=</span> load_dataset<span class=\"token punctuation\">(</span><span class=\"token string\">\"json\"</span><span class=\"token punctuation\">,</span> data_files<span class=\"token operator\">=</span><span class=\"token string\">\"custom_instructions.json\"</span><span class=\"token punctuation\">)</span>\ndataset <span class=\"token operator\">=</span> dataset<span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span>format_instruction<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 학습 설정</span>\ntraining_args <span class=\"token operator\">=</span> TrainingArguments<span class=\"token punctuation\">(</span>\n    output_dir<span class=\"token operator\">=</span><span class=\"token string\">\"./llama2-7b-custom-lora\"</span><span class=\"token punctuation\">,</span>\n    num_train_epochs<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span>\n    per_device_train_batch_size<span class=\"token operator\">=</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span>\n    gradient_accumulation_steps<span class=\"token operator\">=</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span>\n    learning_rate<span class=\"token operator\">=</span><span class=\"token number\">2e-4</span><span class=\"token punctuation\">,</span>\n    warmup_steps<span class=\"token operator\">=</span><span class=\"token number\">100</span><span class=\"token punctuation\">,</span>\n    logging_steps<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span>\n    save_strategy<span class=\"token operator\">=</span><span class=\"token string\">\"epoch\"</span><span class=\"token punctuation\">,</span>\n    fp16<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n    optim<span class=\"token operator\">=</span><span class=\"token string\">\"paged_adamw_8bit\"</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># 메모리 효율적인 옵티마이저</span>\n    gradient_checkpointing<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n    max_grad_norm<span class=\"token operator\">=</span><span class=\"token number\">0.3</span><span class=\"token punctuation\">,</span>\n    lr_scheduler_type<span class=\"token operator\">=</span><span class=\"token string\">\"cosine\"</span>\n<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 학습 실행</span>\ntrainer <span class=\"token operator\">=</span> Trainer<span class=\"token punctuation\">(</span>\n    model<span class=\"token operator\">=</span>model<span class=\"token punctuation\">,</span>\n    args<span class=\"token operator\">=</span>training_args<span class=\"token punctuation\">,</span>\n    train_dataset<span class=\"token operator\">=</span>dataset<span class=\"token punctuation\">[</span><span class=\"token string\">\"train\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n    tokenizer<span class=\"token operator\">=</span>tokenizer<span class=\"token punctuation\">,</span>\n    data_collator<span class=\"token operator\">=</span>DataCollatorForLanguageModeling<span class=\"token punctuation\">(</span>tokenizer<span class=\"token punctuation\">,</span> mlm<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">)</span>\n\ntrainer<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># LoRA 가중치만 저장 (약 17MB)</span>\nmodel<span class=\"token punctuation\">.</span>save_pretrained<span class=\"token punctuation\">(</span><span class=\"token string\">\"./llama2-7b-custom-lora\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h3 id=\"qlora-더-적은-메모리로-파인튜닝\">QLoRA: 더 적은 메모리로 파인튜닝</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># QLoRA 설정 (4-bit 양자화 + LoRA)</span>\nQLORA_CONFIG <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token string\">\"memory_usage\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"7B model full finetune\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"~120GB VRAM\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"7B model LoRA\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"~16GB VRAM\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"7B model QLoRA\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"~6GB VRAM\"</span>  <span class=\"token comment\"># 훨씬 적은 메모리!</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"quality_comparison\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"full_finetune\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"100%\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"lora\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"~99%\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"qlora\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"~97%\"</span>  <span class=\"token comment\"># 약간의 품질 손실</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"training_speed\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"full_finetune\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"1x\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"lora\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"2-3x faster\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"qlora\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"1.5-2x faster\"</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\"># 실제 QLoRA 학습 경험</span>\nQLORA_EXPERIENCE <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token string\">\"hardware\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"RTX 3090 (24GB)\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"model\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"LLaMA 2 13B\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"dataset\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"5,000 instruction pairs\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"training_time\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"~4 hours\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"result\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"도메인 특화 성능 크게 향상\"</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<h2 id=\"vllm-프로덕션-서빙\">vLLM: 프로덕션 서빙</h2>\n<p>로컬에서 돌리는 것과 서비스로 제공하는 것은 다릅니다. <a href=\"https://github.com/vllm-project/vllm\">vLLM</a>은 LLM 서빙을 위한 최적의 도구입니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> vllm <span class=\"token keyword\">import</span> LLM<span class=\"token punctuation\">,</span> SamplingParams\n\n<span class=\"token comment\"># vLLM으로 모델 로드</span>\nllm <span class=\"token operator\">=</span> LLM<span class=\"token punctuation\">(</span>\n    model<span class=\"token operator\">=</span><span class=\"token string\">\"meta-llama/Llama-2-13b-chat-hf\"</span><span class=\"token punctuation\">,</span>\n    tensor_parallel_size<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># 2개 GPU에 분산</span>\n    gpu_memory_utilization<span class=\"token operator\">=</span><span class=\"token number\">0.9</span><span class=\"token punctuation\">,</span>\n    max_model_len<span class=\"token operator\">=</span><span class=\"token number\">4096</span>\n<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 샘플링 파라미터</span>\nsampling_params <span class=\"token operator\">=</span> SamplingParams<span class=\"token punctuation\">(</span>\n    temperature<span class=\"token operator\">=</span><span class=\"token number\">0.7</span><span class=\"token punctuation\">,</span>\n    top_p<span class=\"token operator\">=</span><span class=\"token number\">0.95</span><span class=\"token punctuation\">,</span>\n    max_tokens<span class=\"token operator\">=</span><span class=\"token number\">512</span><span class=\"token punctuation\">,</span>\n    presence_penalty<span class=\"token operator\">=</span><span class=\"token number\">0.0</span><span class=\"token punctuation\">,</span>\n    frequency_penalty<span class=\"token operator\">=</span><span class=\"token number\">0.0</span>\n<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 배치 추론 (vLLM의 핵심 장점)</span>\nprompts <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>\n    <span class=\"token string\">\"[INST] Python으로 퀵소트 구현해줘 [/INST]\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"[INST] Docker란 무엇인가요? [/INST]\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"[INST] REST API 설계 원칙을 설명해줘 [/INST]\"</span>\n<span class=\"token punctuation\">]</span>\n\noutputs <span class=\"token operator\">=</span> llm<span class=\"token punctuation\">.</span>generate<span class=\"token punctuation\">(</span>prompts<span class=\"token punctuation\">,</span> sampling_params<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">for</span> output <span class=\"token keyword\">in</span> outputs<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"Prompt: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>output<span class=\"token punctuation\">.</span>prompt<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token format-spec\">50]</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">...\"</span></span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"Response: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>output<span class=\"token punctuation\">.</span>outputs<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>text<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token format-spec\">100]</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">...\"</span></span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"---\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>vLLM이 빠른 이유입니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">VLLM_OPTIMIZATIONS <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token string\">\"PagedAttention\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"description\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"KV 캐시를 페이지 단위로 관리\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"benefit\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"메모리 낭비 95% 감소\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"analogy\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"OS의 가상 메모리 기법을 LLM에 적용\"</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"Continuous Batching\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"description\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"요청이 완료되면 즉시 새 요청 처리\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"benefit\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"처리량 2-4배 향상\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"vs_static\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"기존: 가장 긴 응답 기다림\"</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"Tensor Parallelism\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"description\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"여러 GPU에 모델 분산\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"benefit\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"큰 모델 서빙 가능\"</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\"># vLLM 서버 실행 (OpenAI 호환 API)</span>\n<span class=\"token comment\"># python -m vllm.entrypoints.openai.api_server \\</span>\n<span class=\"token comment\">#     --model meta-llama/Llama-2-13b-chat-hf \\</span>\n<span class=\"token comment\">#     --tensor-parallel-size 2</span>\n\n<span class=\"token comment\"># 클라이언트에서 사용 (OpenAI SDK 그대로 사용 가능!)</span>\n<span class=\"token keyword\">import</span> openai\n\nclient <span class=\"token operator\">=</span> openai<span class=\"token punctuation\">.</span>OpenAI<span class=\"token punctuation\">(</span>\n    base_url<span class=\"token operator\">=</span><span class=\"token string\">\"http://localhost:8000/v1\"</span><span class=\"token punctuation\">,</span>\n    api_key<span class=\"token operator\">=</span><span class=\"token string\">\"dummy\"</span>  <span class=\"token comment\"># vLLM은 인증 불필요</span>\n<span class=\"token punctuation\">)</span>\n\nresponse <span class=\"token operator\">=</span> client<span class=\"token punctuation\">.</span>chat<span class=\"token punctuation\">.</span>completions<span class=\"token punctuation\">.</span>create<span class=\"token punctuation\">(</span>\n    model<span class=\"token operator\">=</span><span class=\"token string\">\"meta-llama/Llama-2-13b-chat-hf\"</span><span class=\"token punctuation\">,</span>\n    messages<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">{</span><span class=\"token string\">\"role\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"user\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"content\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"Hello!\"</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">)</span></code></pre></div>\n<h2 id=\"실제-프로젝트-경험\">실제 프로젝트 경험</h2>\n<h3 id=\"도메인-특화-챗봇-구축\">도메인 특화 챗봇 구축</h3>\n<p>사내 기술 문서 기반 Q&#x26;A 봇을 만들었습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># RAG (Retrieval-Augmented Generation) 구조</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">DomainChatbot</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    LLaMA 2 + RAG 기반 도메인 특화 챗봇\n\n    구조:\n    1. 문서 임베딩 (Sentence Transformers)\n    2. 벡터 검색 (FAISS)\n    3. LLaMA 2로 응답 생성\n    \"\"\"</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> llm_model<span class=\"token punctuation\">,</span> embedding_model<span class=\"token punctuation\">,</span> vector_store<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>llm <span class=\"token operator\">=</span> llm_model\n        self<span class=\"token punctuation\">.</span>embedder <span class=\"token operator\">=</span> embedding_model\n        self<span class=\"token punctuation\">.</span>vector_store <span class=\"token operator\">=</span> vector_store\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">retrieve_context</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> query<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">,</span> top_k<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span> <span class=\"token operator\">=</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token triple-quoted-string string\">\"\"\"관련 문서 검색\"\"\"</span>\n        query_embedding <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>embedder<span class=\"token punctuation\">.</span>encode<span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">)</span>\n        docs <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>vector_store<span class=\"token punctuation\">.</span>search<span class=\"token punctuation\">(</span>query_embedding<span class=\"token punctuation\">,</span> top_k<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> docs\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">generate_response</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> query<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\"># 1. 관련 문서 검색</span>\n        context_docs <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>retrieve_context<span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">)</span>\n        context <span class=\"token operator\">=</span> <span class=\"token string\">\"\\n\\n\"</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>doc<span class=\"token punctuation\">.</span>text <span class=\"token keyword\">for</span> doc <span class=\"token keyword\">in</span> context_docs<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># 2. 프롬프트 구성</span>\n        prompt <span class=\"token operator\">=</span> <span class=\"token string-interpolation\"><span class=\"token string\">f\"\"\"[INST] &lt;&lt;SYS>>\nYou are a helpful assistant that answers questions based on the provided context.\nIf the answer is not in the context, say \"I don't have information about that.\"\n&lt;&lt;/SYS>>\n\nContext:\n</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>context<span class=\"token punctuation\">}</span></span><span class=\"token string\">\n\nQuestion: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>query<span class=\"token punctuation\">}</span></span><span class=\"token string\">\n[/INST]\"\"\"</span></span>\n\n        <span class=\"token comment\"># 3. LLaMA로 응답 생성</span>\n        response <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>llm<span class=\"token punctuation\">.</span>generate<span class=\"token punctuation\">(</span>prompt<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> response\n\n<span class=\"token comment\"># 실제 성능</span>\nRAG_CHATBOT_RESULTS <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token string\">\"accuracy\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"87% (내부 테스트셋 기준)\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"latency\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"평균 2.3초\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"user_satisfaction\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"4.2/5.0\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"cost_vs_gpt4\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"90% 비용 절감\"</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<h3 id=\"코드-리뷰-어시스턴트\">코드 리뷰 어시스턴트</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># CodeLlama를 활용한 코드 리뷰</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">CodeReviewAssistant</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> model_path<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>llm <span class=\"token operator\">=</span> Llama<span class=\"token punctuation\">(</span>\n            model_path<span class=\"token operator\">=</span>model_path<span class=\"token punctuation\">,</span>\n            n_ctx<span class=\"token operator\">=</span><span class=\"token number\">8192</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># 코드는 긴 컨텍스트 필요</span>\n            n_gpu_layers<span class=\"token operator\">=</span><span class=\"token number\">40</span>\n        <span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">review_code</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> code<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">,</span> language<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"python\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        prompt <span class=\"token operator\">=</span> <span class=\"token string-interpolation\"><span class=\"token string\">f\"\"</span></span>\"<span class=\"token punctuation\">[</span>INST<span class=\"token punctuation\">]</span> Review the following <span class=\"token punctuation\">{</span>language<span class=\"token punctuation\">}</span> code<span class=\"token punctuation\">.</span>\nPoint out<span class=\"token punctuation\">:</span>\n<span class=\"token number\">1.</span> Potential bugs\n<span class=\"token number\">2.</span> Security issues\n<span class=\"token number\">3.</span> Performance improvements\n<span class=\"token number\">4.</span> Code style issues\n\n```<span class=\"token punctuation\">{</span>language<span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">{</span>code<span class=\"token punctuation\">}</span></code></pre></div>\n<p>[/INST]\"\"\"</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">    response = self.llm(\n        prompt,\n        max_tokens=1024,\n        temperature=0.3,  # 코드 리뷰는 낮은 temperature\n        stop=[\"[INST]\"]\n    )\n    return response[\"choices\"][0][\"text\"]\n\ndef suggest_tests(self, code: str):\n    prompt = f\"\"\"[INST] Generate unit tests for the following code:</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token punctuation\">{</span>code<span class=\"token punctuation\">}</span></code></pre></div>\n<p>Use pytest framework. Include edge cases.\n[/INST]\"\"\"</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">    response = self.llm(prompt, max_tokens=2048, temperature=0.3)\n    return response[\"choices\"][0][\"text\"]</code></pre></div>\n<h1 id=\"실제-사용-결과\">실제 사용 결과</h1>\n<p>CODE_REVIEW_RESULTS = {\n\"bug_detection_rate\": \"72%\",\n\"false_positive_rate\": \"18%\",\n\"useful_suggestions_rate\": \"65%\",\n\"comparison_to_gpt4\": \"GPT-4 대비 85% 수준\"\n}</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">\n## 한계와 현실\n\nLLaMA 기반 모델도 한계가 있습니다.\n\n```python\nLLAMA_LIMITATIONS = {\n    \"vs_gpt4\": {\n        \"complex_reasoning\": \"GPT-4가 여전히 우세\",\n        \"long_context\": \"GPT-4: 128K, LLaMA 2: 4K (기본)\",\n        \"instruction_following\": \"GPT-4가 더 정교함\",\n        \"hallucination\": \"비슷한 수준\"\n    },\n    \"operational_challenges\": {\n        \"gpu_cost\": \"13B+ 모델은 GPU 필요\",\n        \"maintenance\": \"직접 서버 운영 필요\",\n        \"updates\": \"OpenAI처럼 자동 업데이트 없음\",\n        \"expertise\": \"ML 지식 필요\"\n    },\n    \"when_to_use_api\": [\n        \"프로토타이핑 단계\",\n        \"트래픽이 적을 때\",\n        \"최고 품질이 필요할 때\",\n        \"복잡한 추론이 필요할 때\"\n    ],\n    \"when_to_use_local\": [\n        \"프라이버시가 중요할 때\",\n        \"대량 처리가 필요할 때\",\n        \"커스터마이징이 필요할 때\",\n        \"비용 최적화가 중요할 때\"\n    ]\n}</code></pre></div>\n<h2 id=\"비용-분석\">비용 분석</h2>\n<p>실제 운영 비용을 비교해봤습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">COST_COMPARISON <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token string\">\"openai_api\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"model\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"GPT-4\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"cost_per_1k_tokens\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token string\">\"input\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"$0.03\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"output\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"$0.06\"</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"monthly_1m_requests\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"~$4,500\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"pros\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"관리 불필요\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"최고 품질\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"cons\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"비용\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"종속성\"</span><span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"self_hosted_vllm\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"model\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"LLaMA 2 70B\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"infrastructure\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token string\">\"gpu\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"2x A100 80GB\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"monthly_cost\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"~$3,000 (클라우드)\"</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"cost_per_1k_tokens\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"~$0.001\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"monthly_1m_requests\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"~$3,100 (인프라 포함)\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"pros\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"저렴한 토큰 비용\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"커스터마이징\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"cons\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"초기 설정\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"운영 부담\"</span><span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"self_hosted_7b\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"model\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"LLaMA 2 7B\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"infrastructure\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token string\">\"gpu\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"1x RTX 4090\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"monthly_cost\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"~$200 (전기세)\"</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"cost_per_1k_tokens\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"~$0.0001\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"monthly_1m_requests\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"~$200\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"pros\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"매우 저렴\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"빠른 응답\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"cons\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"품질 제한\"</span><span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\"># 손익분기점 분석</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">calculate_breakeven</span><span class=\"token punctuation\">(</span>daily_requests<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    api_cost <span class=\"token operator\">=</span> daily_requests <span class=\"token operator\">*</span> <span class=\"token number\">0.04</span> <span class=\"token operator\">*</span> <span class=\"token number\">30</span>  <span class=\"token comment\"># GPT-4, 평균 1K 토큰</span>\n    self_hosted_cost <span class=\"token operator\">=</span> <span class=\"token number\">3000</span>  <span class=\"token comment\"># A100 2대 월 비용</span>\n\n    <span class=\"token keyword\">if</span> api_cost <span class=\"token operator\">></span> self_hosted_cost<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token string\">\"Self-hosted가 유리\"</span>\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token string\">\"API가 유리\"</span>\n\n<span class=\"token comment\"># 하루 2,500 요청 이상이면 self-hosted가 유리</span></code></pre></div>\n<h2 id=\"2023년-정리\">2023년 정리</h2>\n<p>LLaMA로 시작해서 LLaMA 2까지, 오픈소스 LLM이 \"쓸만한 수준\"에 도달했습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">YEAR_2023_SUMMARY <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token string\">\"key_milestones\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span>\n        <span class=\"token string\">\"2023.02: LLaMA 공개\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"2023.03: Alpaca, Vicuna 등장\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"2023.04: llama.cpp 등장\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"2023.07: LLaMA 2 공개 (상업적 사용 허용)\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"2023.08: CodeLlama 공개\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"2023.10: Mistral 7B 공개 (LLaMA 급 성능, 더 작은 모델)\"</span>\n    <span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"paradigm_shift\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"before\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"API 종속, 비용 부담, 커스터마이징 불가\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"after\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"자체 운영 가능, 비용 절감, 도메인 특화 가능\"</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"personal_takeaway\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span>\n        <span class=\"token string\">\"GPT-4를 대체하긴 어렵지만, 많은 용도에서 충분\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"프라이버시가 중요한 경우 필수 선택지\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"비용 최적화에 큰 도움\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"ML 엔지니어의 역할이 더 중요해짐\"</span>\n    <span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<h2 id=\"2024년-이후-llama-3의-등장\">2024년 이후: LLaMA 3의 등장</h2>\n<blockquote>\n<p><strong>2024년 4월 업데이트</strong>: 이 글을 쓴 후 Meta가 LLaMA 3를 공개했습니다. 예상이 현실이 되었습니다.</p>\n</blockquote>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">LLAMA_3_RELEASE <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token string\">\"release_date\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"2024년 4월\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"models\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"LLaMA 3 8B\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token string\">\"context\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"8K\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"highlight\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"LLaMA 2 70B와 비슷한 성능\"</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"LLaMA 3 70B\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token string\">\"context\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"8K\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"highlight\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"GPT-4 Turbo에 근접한 벤치마크\"</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"LLaMA 3.1 405B\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token string\">\"release\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"2024년 7월\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"context\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"128K\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"highlight\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"오픈소스 최초 Frontier 급 모델\"</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"key_improvements\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span>\n        <span class=\"token string\">\"15조 토큰 학습 (LLaMA 2의 7배)\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"GQA (Grouped Query Attention) 적용\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"더 나은 instruction following\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"다국어 성능 향상\"</span>\n    <span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<p>\"오픈소스가 GPT-4 수준에 도달할 수 있을까?\"라는 질문에 대해, LLaMA 3.1 405B가 상당 부분 그 답을 보여주었습니다. 물론 GPT-4o나 Claude 3.5 Opus와 직접 비교하면 여전히 차이가 있지만, 격차가 많이 좁혀진 것은 분명합니다.</p>\n<p>\"AI 연구가 민주화됐다\"는 말이 약간 과장이긴 하지만, 방향은 맞다고 생각합니다. 예전에는 빅테크가 아니면 LLM을 만지기 어려웠는데, 이제는 누구나 시도해볼 수 있게 되었습니다.</p>\n<h2 id=\"관련-글\">관련 글</h2>\n<ul>\n<li><a href=\"/posts/gpt3-transformer-innovation\">GPT-3가 바꿔놓은 것들</a></li>\n<li><a href=\"/posts/stable-diffusion-ai-generation-2023\">Stable Diffusion을 실무에 적용해본 경험</a></li>\n<li><a href=\"/posts/stable-diffusion-generative-ai-2023\">SDXL로 텍스처 생성 프로젝트를 진행하면서</a></li>\n</ul>\n<hr>\n<h2 id=\"참고-자료\">참고 자료</h2>\n<ul>\n<li><a href=\"https://arxiv.org/abs/2302.13971\">LLaMA Paper</a></li>\n<li><a href=\"https://arxiv.org/abs/2307.09288\">LLaMA 2 Paper</a></li>\n<li><a href=\"https://arxiv.org/abs/2407.21783\">LLaMA 3 Paper</a></li>\n<li><a href=\"https://github.com/ggerganov/llama.cpp\">llama.cpp</a></li>\n<li><a href=\"https://github.com/vllm-project/vllm\">vLLM</a></li>\n<li><a href=\"https://huggingface.co/docs/peft\">PEFT (LoRA)</a></li>\n<li><a href=\"https://huggingface.co/docs/transformers\">Hugging Face Transformers</a></li>\n<li><a href=\"https://arxiv.org/abs/2305.14314\">QLoRA Paper</a></li>\n</ul>","excerpt":"LLaMA가 바꿔놓은 것들 2023년 2월, Meta가 LLaMA를 공개했습니다. 처음에는 \"그래서 뭐가 달라지나?\"라고 생각했는데, 돌이켜보면 이 모델이 오픈소스 LLM 생태계의 판을 완전히 바꿔놓았습니다. 이 글에서는 2023년 한 해 동안 일어난 변화와 실제 경험을 정리합니다. LLaMA 공개 전과 후 공개 전: API 종속의 시대 LLaMA 이전에…","frontmatter":{"date":"23.11.01","dateISO":"2023-11-01","description":"2023년 오픈소스 LLM 생태계 변화 정리","slug":"/llama-opensource-ecosystem-2023","heroImage":null,"heroImageAlt":null,"tags":["ai"],"title":"LLaMA가 바꿔놓은 것들"},"tableOfContents":"<ul>\n<li>\n<p><a href=\"#llama%EA%B0%80-%EB%B0%94%EA%BF%94%EB%86%93%EC%9D%80-%EA%B2%83%EB%93%A4\">LLaMA가 바꿔놓은 것들</a></p>\n<ul>\n<li>\n<p><a href=\"#llama-%EA%B3%B5%EA%B0%9C-%EC%A0%84%EA%B3%BC-%ED%9B%84\">LLaMA 공개 전과 후</a></p>\n<ul>\n<li><a href=\"#%EA%B3%B5%EA%B0%9C-%EC%A0%84-api-%EC%A2%85%EC%86%8D%EC%9D%98-%EC%8B%9C%EB%8C%80\">공개 전: API 종속의 시대</a></li>\n<li><a href=\"#%EA%B3%B5%EA%B0%9C-%ED%9B%84-%EC%83%88%EB%A1%9C%EC%9A%B4-%EA%B0%80%EB%8A%A5%EC%84%B1\">공개 후: 새로운 가능성</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%EC%83%9D%ED%83%9C%EA%B3%84-%ED%8F%AD%EB%B0%9C\">생태계 폭발</a></p>\n<ul>\n<li><a href=\"#%ED%8C%8C%EC%9D%B8%ED%8A%9C%EB%8B%9D-%EB%AA%A8%EB%8D%B8%EB%93%A4\">파인튜닝 모델들</a></li>\n<li><a href=\"#%ED%9A%A8%EC%9C%A8%EC%84%B1-%EB%8F%84%EA%B5%AC%EB%93%A4\">효율성 도구들</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%EC%8B%A4%EC%A0%9C%EB%A1%9C-%ED%95%B4%EB%B3%B8-%EA%B2%83%EB%93%A4\">실제로 해본 것들</a></p>\n<ul>\n<li><a href=\"#%EB%A1%9C%EC%BB%AC-llm-%EC%8B%A4%ED%96%89\">로컬 LLM 실행</a></li>\n<li><a href=\"#%ED%8C%8C%EC%9D%B8%ED%8A%9C%EB%8B%9D-%EC%8B%9C%EB%8F%84\">파인튜닝 시도</a></li>\n<li><a href=\"#qlora-%EB%8D%94-%EC%A0%81%EC%9D%80-%EB%A9%94%EB%AA%A8%EB%A6%AC%EB%A1%9C-%ED%8C%8C%EC%9D%B8%ED%8A%9C%EB%8B%9D\">QLoRA: 더 적은 메모리로 파인튜닝</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#vllm-%ED%94%84%EB%A1%9C%EB%8D%95%EC%85%98-%EC%84%9C%EB%B9%99\">vLLM: 프로덕션 서빙</a></p>\n</li>\n<li>\n<p><a href=\"#%EC%8B%A4%EC%A0%9C-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-%EA%B2%BD%ED%97%98\">실제 프로젝트 경험</a></p>\n<ul>\n<li><a href=\"#%EB%8F%84%EB%A9%94%EC%9D%B8-%ED%8A%B9%ED%99%94-%EC%B1%97%EB%B4%87-%EA%B5%AC%EC%B6%95\">도메인 특화 챗봇 구축</a></li>\n<li><a href=\"#%EC%BD%94%EB%93%9C-%EB%A6%AC%EB%B7%B0-%EC%96%B4%EC%8B%9C%EC%8A%A4%ED%84%B4%ED%8A%B8\">코드 리뷰 어시스턴트</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%EC%8B%A4%EC%A0%9C-%EC%82%AC%EC%9A%A9-%EA%B2%B0%EA%B3%BC\">실제 사용 결과</a></p>\n<ul>\n<li><a href=\"#%EB%B9%84%EC%9A%A9-%EB%B6%84%EC%84%9D\">비용 분석</a></li>\n<li><a href=\"#2023%EB%85%84-%EC%A0%95%EB%A6%AC\">2023년 정리</a></li>\n<li><a href=\"#2024%EB%85%84-%EC%9D%B4%ED%9B%84-llama-3%EC%9D%98-%EB%93%B1%EC%9E%A5\">2024년 이후: LLaMA 3의 등장</a></li>\n<li><a href=\"#%EA%B4%80%EB%A0%A8-%EA%B8%80\">관련 글</a></li>\n<li><a href=\"#%EC%B0%B8%EA%B3%A0-%EC%9E%90%EB%A3%8C\">참고 자료</a></li>\n</ul>\n</li>\n</ul>"}},"pageContext":{"id":"3e9aa58d-7d33-510f-ae0c-d8a98753b468","frontmatter__slug":"/llama-opensource-ecosystem-2023","previous":"/review-ncsoft","previousTitle":"Review NCSOFT","next":"/vision-devices-large-models-2023","nextTitle":"2023년 Vision Transformer 정리"}},"staticQueryHashes":["12962592","3399079524","3470099541","4097432363","76375841"],"slicesMap":{}}