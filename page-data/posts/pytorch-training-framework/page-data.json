{"componentChunkName":"component---src-templates-post-tsx","path":"/posts/pytorch-training-framework/","result":{"data":{"markdownRemark":{"html":"<h1 id=\"pytorch-학습-프레임워크를-직접-만들어본-이야기\">PyTorch 학습 프레임워크를 직접 만들어본 이야기</h1>\n<p>석사 과정 중에 모션 캡처 데이터로 페이셜 애니메이션 연구를 진행했습니다. 연구 자체보다 환경 세팅에 시간이 더 많이 들어서, 결국 학습 프레임워크를 직접 만들게 되었습니다. 이 글에서는 그 과정에서 배운 것들을 공유하고자 합니다.</p>\n<h2 id=\"왜-만들었나\">왜 만들었나</h2>\n<p>매번 새로운 실험을 시작할 때마다 같은 코드를 복사해서 붙여넣는 것이 비효율적이라고 느꼈습니다. 데이터 로딩, 학습 루프, 체크포인트 저장, 로깅 등 기본적인 구성요소들을 매번 새로 작성하는 것은 시간 낭비였습니다.</p>\n<p>특히 모션 캡처 데이터는 전처리 과정이 까다롭습니다. 결측치 처리, 노이즈 필터링, 시퀀스 길이 맞추기 등 다양한 처리가 필요합니다. 이런 작업들을 한 번 잘 만들어두면 이후 실험에서 재사용할 수 있겠다는 생각이 들었습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 매번 이런 코드를 반복 작성하는 것이 비효율적이었습니다</span>\n<span class=\"token keyword\">for</span> epoch <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>num_epochs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    model<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span> batch <span class=\"token keyword\">in</span> train_loader<span class=\"token punctuation\">:</span>\n        optimizer<span class=\"token punctuation\">.</span>zero_grad<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        outputs <span class=\"token operator\">=</span> model<span class=\"token punctuation\">(</span>batch<span class=\"token punctuation\">)</span>\n        loss <span class=\"token operator\">=</span> criterion<span class=\"token punctuation\">(</span>outputs<span class=\"token punctuation\">,</span> targets<span class=\"token punctuation\">)</span>\n        loss<span class=\"token punctuation\">.</span>backward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        optimizer<span class=\"token punctuation\">.</span>step<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># 검증, 로깅, 체크포인트 저장 등...</span></code></pre></div>\n<h2 id=\"프레임워크-구조\">프레임워크 구조</h2>\n<p>크게 세 가지 모듈로 구성했습니다.</p>\n<h3 id=\"데이터-파이프라인\">데이터 파이프라인</h3>\n<p>모션 캡처 데이터를 효율적으로 처리하기 위한 파이프라인을 구축했습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">MotionDataset</span><span class=\"token punctuation\">(</span>Dataset<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> data_path<span class=\"token punctuation\">,</span> sequence_length<span class=\"token operator\">=</span><span class=\"token number\">120</span><span class=\"token punctuation\">,</span> overlap<span class=\"token operator\">=</span><span class=\"token number\">60</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>data <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>_load_motion_data<span class=\"token punctuation\">(</span>data_path<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>sequences <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>_create_sequences<span class=\"token punctuation\">(</span>sequence_length<span class=\"token punctuation\">,</span> overlap<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">_load_motion_data</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token triple-quoted-string string\">\"\"\"BVH/FBX 파일에서 모션 데이터 로드 및 전처리\"\"\"</span>\n        raw_data <span class=\"token operator\">=</span> load_motion_file<span class=\"token punctuation\">(</span>path<span class=\"token punctuation\">)</span>\n        <span class=\"token comment\"># 결측치 보간</span>\n        interpolated <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>_interpolate_missing_frames<span class=\"token punctuation\">(</span>raw_data<span class=\"token punctuation\">)</span>\n        <span class=\"token comment\"># 노이즈 필터링 (Butterworth filter)</span>\n        filtered <span class=\"token operator\">=</span> butter_lowpass_filter<span class=\"token punctuation\">(</span>interpolated<span class=\"token punctuation\">,</span> cutoff<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> fs<span class=\"token operator\">=</span><span class=\"token number\">60</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> filtered\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">_create_sequences</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> length<span class=\"token punctuation\">,</span> overlap<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token triple-quoted-string string\">\"\"\"오버랩을 고려한 시퀀스 생성\"\"\"</span>\n        sequences <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        stride <span class=\"token operator\">=</span> length <span class=\"token operator\">-</span> overlap\n        <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> length<span class=\"token punctuation\">,</span> stride<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            sequences<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">:</span>i<span class=\"token operator\">+</span>length<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> sequences</code></pre></div>\n<p>주요 기능:</p>\n<ul>\n<li><strong>모션 캡처 데이터 로딩</strong>: BVH, FBX 등 다양한 포맷 지원</li>\n<li><strong>결측치 처리</strong>: Linear interpolation과 Kalman filter를 활용한 보간</li>\n<li><strong>시퀀스 생성</strong>: 학습을 위한 오버랩 시퀀스 생성</li>\n<li><strong>동적 배치 사이징</strong>: 메모리 사용량에 따른 배치 크기 자동 조절</li>\n</ul>\n<h3 id=\"학습-루프-trainer\">학습 루프 (Trainer)</h3>\n<p>기본적인 학습/검증 루프를 추상화하여 재사용 가능하도록 구성했습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">Trainer</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> model<span class=\"token punctuation\">,</span> optimizer<span class=\"token punctuation\">,</span> criterion<span class=\"token punctuation\">,</span> config<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>model <span class=\"token operator\">=</span> model\n        self<span class=\"token punctuation\">.</span>optimizer <span class=\"token operator\">=</span> optimizer\n        self<span class=\"token punctuation\">.</span>criterion <span class=\"token operator\">=</span> criterion\n        self<span class=\"token punctuation\">.</span>config <span class=\"token operator\">=</span> config\n        self<span class=\"token punctuation\">.</span>best_loss <span class=\"token operator\">=</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span><span class=\"token string\">'inf'</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>patience_counter <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">train_epoch</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> train_loader<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>model<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        total_loss <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n\n        <span class=\"token keyword\">for</span> batch_idx<span class=\"token punctuation\">,</span> batch <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>train_loader<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            self<span class=\"token punctuation\">.</span>optimizer<span class=\"token punctuation\">.</span>zero_grad<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n            <span class=\"token comment\"># Forward pass</span>\n            outputs <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>model<span class=\"token punctuation\">(</span>batch<span class=\"token punctuation\">[</span><span class=\"token string\">'input'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>device<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n            loss <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>criterion<span class=\"token punctuation\">(</span>outputs<span class=\"token punctuation\">,</span> batch<span class=\"token punctuation\">[</span><span class=\"token string\">'target'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>device<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n            <span class=\"token comment\"># Backward pass</span>\n            loss<span class=\"token punctuation\">.</span>backward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n            <span class=\"token comment\"># Gradient clipping (모션 데이터는 값 범위가 커서 필수)</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>utils<span class=\"token punctuation\">.</span>clip_grad_norm_<span class=\"token punctuation\">(</span>\n                self<span class=\"token punctuation\">.</span>model<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                self<span class=\"token punctuation\">.</span>config<span class=\"token punctuation\">.</span>grad_clip\n            <span class=\"token punctuation\">)</span>\n\n            self<span class=\"token punctuation\">.</span>optimizer<span class=\"token punctuation\">.</span>step<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n            total_loss <span class=\"token operator\">+=</span> loss<span class=\"token punctuation\">.</span>item<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">return</span> total_loss <span class=\"token operator\">/</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>train_loader<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">check_early_stopping</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> val_loss<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token triple-quoted-string string\">\"\"\"조기 종료 체크\"\"\"</span>\n        <span class=\"token keyword\">if</span> val_loss <span class=\"token operator\">&lt;</span> self<span class=\"token punctuation\">.</span>best_loss<span class=\"token punctuation\">:</span>\n            self<span class=\"token punctuation\">.</span>best_loss <span class=\"token operator\">=</span> val_loss\n            self<span class=\"token punctuation\">.</span>patience_counter <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n            self<span class=\"token punctuation\">.</span>save_checkpoint<span class=\"token punctuation\">(</span><span class=\"token string\">'best_model.pt'</span><span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">return</span> <span class=\"token boolean\">False</span>\n        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n            self<span class=\"token punctuation\">.</span>patience_counter <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n            <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>patience_counter <span class=\"token operator\">>=</span> self<span class=\"token punctuation\">.</span>config<span class=\"token punctuation\">.</span>patience</code></pre></div>\n<p>Trainer가 제공하는 기능:</p>\n<ul>\n<li><strong>기본 train/eval 루프</strong>: 표준적인 학습/검증 사이클</li>\n<li><strong>조기 종료 (Early Stopping)</strong>: Validation loss 기반 자동 중단</li>\n<li><strong>학습률 스케줄링</strong>: Warmup, Cosine Annealing 등 지원</li>\n<li><strong>체크포인트 자동 저장</strong>: Best model 및 주기적 저장</li>\n<li><strong>Gradient Clipping</strong>: 모션 데이터 특성상 gradient 폭발 방지</li>\n</ul>\n<h3 id=\"설정-관리-config\">설정 관리 (Config)</h3>\n<p>실험별 설정을 YAML 파일로 관리하여 재현 가능한 실험 환경을 구축했습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token comment\"># configs/facial_animation_v1.yaml</span>\n<span class=\"token key atrule\">experiment</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"facial_motion_transformer\"</span>\n  <span class=\"token key atrule\">seed</span><span class=\"token punctuation\">:</span> <span class=\"token number\">42</span>\n\n<span class=\"token key atrule\">model</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">type</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"transformer\"</span>\n  <span class=\"token key atrule\">d_model</span><span class=\"token punctuation\">:</span> <span class=\"token number\">256</span>\n  <span class=\"token key atrule\">nhead</span><span class=\"token punctuation\">:</span> <span class=\"token number\">8</span>\n  <span class=\"token key atrule\">num_encoder_layers</span><span class=\"token punctuation\">:</span> <span class=\"token number\">6</span>\n  <span class=\"token key atrule\">dropout</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0.1</span>\n\n<span class=\"token key atrule\">training</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">batch_size</span><span class=\"token punctuation\">:</span> <span class=\"token number\">32</span>\n  <span class=\"token key atrule\">learning_rate</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0.0001</span>\n  <span class=\"token key atrule\">num_epochs</span><span class=\"token punctuation\">:</span> <span class=\"token number\">200</span>\n  <span class=\"token key atrule\">patience</span><span class=\"token punctuation\">:</span> <span class=\"token number\">20</span>\n  <span class=\"token key atrule\">grad_clip</span><span class=\"token punctuation\">:</span> <span class=\"token number\">1.0</span>\n\n<span class=\"token key atrule\">data</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">sequence_length</span><span class=\"token punctuation\">:</span> <span class=\"token number\">120</span>\n  <span class=\"token key atrule\">overlap</span><span class=\"token punctuation\">:</span> <span class=\"token number\">60</span>\n  <span class=\"token key atrule\">train_ratio</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0.8</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> dataclasses <span class=\"token keyword\">import</span> dataclass\n<span class=\"token keyword\">from</span> omegaconf <span class=\"token keyword\">import</span> OmegaConf\n\n<span class=\"token decorator annotation punctuation\">@dataclass</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Config</span><span class=\"token punctuation\">:</span>\n    experiment<span class=\"token punctuation\">:</span> <span class=\"token builtin\">dict</span>\n    model<span class=\"token punctuation\">:</span> <span class=\"token builtin\">dict</span>\n    training<span class=\"token punctuation\">:</span> <span class=\"token builtin\">dict</span>\n    data<span class=\"token punctuation\">:</span> <span class=\"token builtin\">dict</span>\n\n    <span class=\"token decorator annotation punctuation\">@classmethod</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">from_yaml</span><span class=\"token punctuation\">(</span>cls<span class=\"token punctuation\">,</span> path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> OmegaConf<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span>path<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">save</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        OmegaConf<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> path<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 사용 예시</span>\nconfig <span class=\"token operator\">=</span> Config<span class=\"token punctuation\">.</span>from_yaml<span class=\"token punctuation\">(</span><span class=\"token string\">'configs/facial_animation_v1.yaml'</span><span class=\"token punctuation\">)</span>\nset_seed<span class=\"token punctuation\">(</span>config<span class=\"token punctuation\">.</span>experiment<span class=\"token punctuation\">.</span>seed<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 재현 가능성 보장</span></code></pre></div>\n<h2 id=\"실험-관리와-로깅\">실험 관리와 로깅</h2>\n<p>실험 결과를 추적하고 비교하기 위해 <a href=\"https://wandb.ai/\">Weights &#x26; Biases</a>를 통합했습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> wandb\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">ExperimentLogger</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> config<span class=\"token punctuation\">,</span> project_name<span class=\"token operator\">=</span><span class=\"token string\">\"motion-research\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>run <span class=\"token operator\">=</span> wandb<span class=\"token punctuation\">.</span>init<span class=\"token punctuation\">(</span>\n            project<span class=\"token operator\">=</span>project_name<span class=\"token punctuation\">,</span>\n            config<span class=\"token operator\">=</span>OmegaConf<span class=\"token punctuation\">.</span>to_container<span class=\"token punctuation\">(</span>config<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            name<span class=\"token operator\">=</span>config<span class=\"token punctuation\">.</span>experiment<span class=\"token punctuation\">.</span>name\n        <span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">log_metrics</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> metrics<span class=\"token punctuation\">,</span> step<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        wandb<span class=\"token punctuation\">.</span>log<span class=\"token punctuation\">(</span>metrics<span class=\"token punctuation\">,</span> step<span class=\"token operator\">=</span>step<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">log_animation</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> motion_data<span class=\"token punctuation\">,</span> name<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token triple-quoted-string string\">\"\"\"생성된 모션을 시각화하여 로깅\"\"\"</span>\n        video <span class=\"token operator\">=</span> render_motion_to_video<span class=\"token punctuation\">(</span>motion_data<span class=\"token punctuation\">)</span>\n        wandb<span class=\"token punctuation\">.</span>log<span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span>name<span class=\"token punctuation\">:</span> wandb<span class=\"token punctuation\">.</span>Video<span class=\"token punctuation\">(</span>video<span class=\"token punctuation\">,</span> fps<span class=\"token operator\">=</span><span class=\"token number\">30</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h2 id=\"실제-효과\">실제 효과</h2>\n<p>프레임워크를 구축한 후 확실히 연구 효율이 향상되었습니다.</p>\n<table>\n<thead>\n<tr>\n<th>항목</th>\n<th>이전</th>\n<th>이후</th>\n<th>개선율</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>실험 설정 시간</td>\n<td>2.5시간</td>\n<td>1시간</td>\n<td>60% 단축</td>\n</tr>\n<tr>\n<td>새 모델 테스트</td>\n<td>하루</td>\n<td>반나절</td>\n<td>50% 단축</td>\n</tr>\n<tr>\n<td>버그 발생률</td>\n<td>높음</td>\n<td>낮음</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<p>숫자로 보면 60% 정도 단축되었는데, 체감상으로는 그 이상이었습니다. 매번 \"이전에 어떻게 했더라?\"하며 옛날 코드를 찾아보는 시간이 없어지고, 실험 재현이 YAML 파일 하나로 가능해졌기 때문입니다.</p>\n<h2 id=\"아쉬운-점과-배운-것\">아쉬운 점과 배운 것</h2>\n<p>솔직히 지금 돌아보면 부끄러운 부분도 있습니다. 당시에는 <a href=\"https://lightning.ai/\">PyTorch Lightning</a>이나 <a href=\"https://huggingface.co/docs/transformers/main_classes/trainer\">Hugging Face Trainer</a> 같은 훌륭한 도구들이 이미 존재했는데, 그런 것들을 충분히 알아보지 않고 직접 만들었습니다.</p>\n<p>만약 그때 이런 도구들을 알았다면 굳이 직접 만들지 않았을 것 같습니다. 하지만 직접 만들면서 얻은 것도 있습니다:</p>\n<ol>\n<li>\n<p><strong>데이터 로딩 최적화에 대한 이해</strong>: <code class=\"language-text\">DataLoader</code>의 <code class=\"language-text\">num_workers</code>, <code class=\"language-text\">pin_memory</code>, <code class=\"language-text\">prefetch_factor</code> 등의 옵션이 성능에 미치는 영향을 직접 체감했습니다.</p>\n</li>\n<li>\n<p><strong>메모리 관리</strong>: Gradient accumulation, mixed precision training 등을 직접 구현하면서 GPU 메모리 관리에 대해 깊이 이해하게 되었습니다.</p>\n</li>\n<li>\n<p><strong>디버깅 능력</strong>: 학습이 잘 안 될 때 어디서 문제가 생기는지 파악하는 능력이 향상되었습니다.</p>\n</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 직접 구현하면서 배운 메모리 최적화 기법</span>\n<span class=\"token keyword\">from</span> torch<span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">.</span>amp <span class=\"token keyword\">import</span> autocast<span class=\"token punctuation\">,</span> GradScaler\n\nscaler <span class=\"token operator\">=</span> GradScaler<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">with</span> autocast<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    outputs <span class=\"token operator\">=</span> model<span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">)</span>\n    loss <span class=\"token operator\">=</span> criterion<span class=\"token punctuation\">(</span>outputs<span class=\"token punctuation\">,</span> targets<span class=\"token punctuation\">)</span>\n\nscaler<span class=\"token punctuation\">.</span>scale<span class=\"token punctuation\">(</span>loss<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>backward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nscaler<span class=\"token punctuation\">.</span>step<span class=\"token punctuation\">(</span>optimizer<span class=\"token punctuation\">)</span>\nscaler<span class=\"token punctuation\">.</span>update<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h2 id=\"현재는\">현재는</h2>\n<p>지금은 PyTorch Lightning을 주로 사용합니다. 제가 만든 것보다 훨씬 완성도가 높고, 커뮤니티 지원도 활발합니다. 하지만 당시에는 직접 만든 프레임워크가 필요했고, 석사 연구를 끝내는 데 큰 도움이 되었기 때문에 후회는 없습니다.</p>\n<h2 id=\"교훈\">교훈</h2>\n<p>이 경험에서 얻은 교훈을 정리하면 다음과 같습니다:</p>\n<ol>\n<li>\n<p><strong>표준 도구부터 찾아보자</strong>: 바퀴를 재발명하기 전에 이미 존재하는 솔루션이 있는지 충분히 조사해야 합니다.</p>\n</li>\n<li>\n<p><strong>그래도 직접 만들면 배우긴 한다</strong>: 삽질도 학습입니다. 추상화된 도구를 쓰기만 하면 내부 동작을 이해하기 어렵습니다.</p>\n</li>\n<li>\n<p><strong>자동화에 투자하는 건 남는 장사</strong>: 처음에는 시간이 들어도 나중에 충분히 회수됩니다.</p>\n</li>\n<li>\n<p><strong>설정 관리와 재현성이 중요하다</strong>: 실험 결과를 신뢰하려면 동일한 설정으로 동일한 결과가 나와야 합니다.</p>\n</li>\n</ol>\n<p>마지막으로, 연구나 프로젝트를 진행할 때 \"이 작업을 앞으로 몇 번이나 반복하게 될까?\"를 생각해보시는 것을 권장합니다. 두세 번 이상이라면 자동화나 추상화에 투자하는 것이 결국 더 효율적입니다.</p>","excerpt":"PyTorch 학습 프레임워크를 직접 만들어본 이야기 석사 과정 중에 모션 캡처 데이터로 페이셜 애니메이션 연구를 진행했습니다. 연구 자체보다 환경 세팅에 시간이 더 많이 들어서, 결국 학습 프레임워크를 직접 만들게 되었습니다. 이 글에서는 그 과정에서 배운 것들을 공유하고자 합니다. 왜 만들었나 매번 새로운 실험을 시작할 때마다 같은 코드를 복사해서 붙…","frontmatter":{"date":"21.02.28","dateISO":"2021-02-28","description":"석사 연구하면서 매번 반복되는 코드에 지쳐서 만든 프레임워크","slug":"/pytorch-training-framework","heroImage":null,"heroImageAlt":null,"tags":["ai","dev"],"title":"PyTorch 학습 프레임워크를 직접 만들어본 이야기"},"tableOfContents":"<ul>\n<li>\n<p><a href=\"#pytorch-%ED%95%99%EC%8A%B5-%ED%94%84%EB%A0%88%EC%9E%84%EC%9B%8C%ED%81%AC%EB%A5%BC-%EC%A7%81%EC%A0%91-%EB%A7%8C%EB%93%A4%EC%96%B4%EB%B3%B8-%EC%9D%B4%EC%95%BC%EA%B8%B0\">PyTorch 학습 프레임워크를 직접 만들어본 이야기</a></p>\n<ul>\n<li>\n<p><a href=\"#%EC%99%9C-%EB%A7%8C%EB%93%A4%EC%97%88%EB%82%98\">왜 만들었나</a></p>\n</li>\n<li>\n<p><a href=\"#%ED%94%84%EB%A0%88%EC%9E%84%EC%9B%8C%ED%81%AC-%EA%B5%AC%EC%A1%B0\">프레임워크 구조</a></p>\n<ul>\n<li><a href=\"#%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8\">데이터 파이프라인</a></li>\n<li><a href=\"#%ED%95%99%EC%8A%B5-%EB%A3%A8%ED%94%84-trainer\">학습 루프 (Trainer)</a></li>\n<li><a href=\"#%EC%84%A4%EC%A0%95-%EA%B4%80%EB%A6%AC-config\">설정 관리 (Config)</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%EC%8B%A4%ED%97%98-%EA%B4%80%EB%A6%AC%EC%99%80-%EB%A1%9C%EA%B9%85\">실험 관리와 로깅</a></p>\n</li>\n<li>\n<p><a href=\"#%EC%8B%A4%EC%A0%9C-%ED%9A%A8%EA%B3%BC\">실제 효과</a></p>\n</li>\n<li>\n<p><a href=\"#%EC%95%84%EC%89%AC%EC%9A%B4-%EC%A0%90%EA%B3%BC-%EB%B0%B0%EC%9A%B4-%EA%B2%83\">아쉬운 점과 배운 것</a></p>\n</li>\n<li>\n<p><a href=\"#%ED%98%84%EC%9E%AC%EB%8A%94\">현재는</a></p>\n</li>\n<li>\n<p><a href=\"#%EA%B5%90%ED%9B%88\">교훈</a></p>\n</li>\n</ul>\n</li>\n</ul>"}},"pageContext":{"id":"c07d7b37-6915-5742-9e4d-b557feabaad2","frontmatter__slug":"/pytorch-training-framework","previous":"/technical-research-personnel","previousTitle":"전문연구요원으로 편입하기","next":"/review-2017","nextTitle":"Review 2017"}},"staticQueryHashes":["12962592","3399079524","3470099541","4097432363","76375841"],"slicesMap":{}}